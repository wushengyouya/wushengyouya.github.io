[{"content":"100 Go Mistakes And How To Avoid Them 1、避免使用遮挡变量\nvar i func get(){ i := 1 } 2、通过避免嵌套层级并将主路径保持在左侧\n3、init函数不能处理error，当有多个init函数先加载依赖项的init(按照文件名字母表的顺序)\n4、抽象是被发现的，而不是创建的。\n5、接口尽量在使用端，而不是在生产端\n6、函数不应该返回抽象而是具体的实现，而参数尽可能的使用接口作为参数\n7、尽量不使用any类型，因为它提供有意思的信息，尽在需要进行序列化的使用any\n8、当有多个参数需要配置时，可以采用功能选项模式。(function option)\n9、创建包名时应该可以直观的明白这个包时做什么的，避免使用泛化包名如util、base、common\n10、对于可以在外部访问的变量与函数都需要注释\n变量和常量: 注释用途和内容 函数和方法：注释函数用途而非实现方式 11、使用静态代码分析工具检测代码如vet、golangci-lint\n12、在go中0o代表8进制,0B | 0b代表二进制,0x代表十六进制,i后缀代表虚数\n13、go中整数上溢和下溢都是隐式的，可以使用math.MaxInt,math.MinInt,math.MaxUint构建函数检测\n14、浮点数在加减运算时应将数量级相近的操作分组以提高准确性，乘除运算应在加减运算前进行以提高准确性\n切片 切片的长度是当前可以获取的元素数，容量是可以存储的元素数。当元素存储满时底层会创建一个新的数组，容量在元素在1024以内成倍扩容，超过后每次扩容1/4 当创建切片时如果已知长度，make时指定长度，减少内存分配提升性能。同样适用于创建map的时候 复制一个切片到另一个切片使用copy函数，复制的元素数取决于两个切片中最小的长度 str[1:5]使用切片表达式缩减切片，底层都是指向同一个数组，如果缩减一个大切片时可能会发生内存泄漏。可以使用copy或\n完整的切片表达式str[1:5:2]缩减大切片必须使用copy 在处理切片时需要记住，如果元素是指针或者是包含指针资源的结构体，这些元素将不会被gc回收，使用下面方法避免内存泄漏。\n清除方法: 1.手动置为nil 2.使用copy而不是reslice // 示例1：指针切片 // 创建包含指针的切片 items := make([]*Item, 0, 100) // 添加一些指针元素 items = append(items, \u0026amp;Item{data: \u0026#34;data1\u0026#34;}) items = append(items, \u0026amp;Item{data: \u0026#34;data2\u0026#34;}) // 假设我们\u0026#34;删除\u0026#34;第一个元素 // 手动清除方法 items[0] = nil // 使用copy copy(item[0:],item[1:]) items = items[1:] // 现在 items 只有 data2 // 问题：底层数组仍然引用着 data1 的指针！ // data1 指向的内存不会被GC回收 /////////////////////////////////////////////////////// // 示例2：包含指针字段的结构体 // 问题：底层数组仍然引用着 data1 的指针！ // data1 指向的内存不会被GC回收 type User struct { Name string Data *Data // 指针字段！ } users := make([]User, 0, 10) users = append(users, User{Name: \u0026#34;Alice\u0026#34;, Data: \u0026amp;Data{value: 100}}) // 删除元素后，Data指针仍然被底层数组引用 users = users[1:] 使用append后，如果结果切片的长度小于容量，会改变原始切片 func main(){ s := []int{1, 2, 3} f(s[:2]) fmt.Println(s) // [1,2,10] } func f(s []int){ _ = append(s, 10) } /* // append操作分析： 1. 检查容量：len=2, cap=3，容量足够 2. 不创建新数组，直接使用原底层数组 3. 在原底层数组索引2位置写入10 4. 返回新切片：len=3, cap=3 内存布局变化: 索引: 0 1 2 前: [1] [2] [3] 后: [1] [2] [10] // 索引2的值被覆盖了！ // 注意：_ = append(s, 10) // 虽然我们忽略了返回值，但底层数组已经被修改了！ */ 记住多个切片可能共享同一个底层数组 检查切片是否包含元素使用len函数，nil与empty切片都返回0.同样适用于map 16、map只会增长不会进行收缩，如果要避免内存泄漏，可以使用指针存储或者创建一个新map\n17、使用==或!=可以对boolean,numeral,string,pointer,channel,struct进行比较，对于是maps和slice可以使用reflect.DeepEqual进行比较\n18、for...range中所有值皆为复制的，如果想要修改值使用索引访问，或者是循环的指针\n19、range 后面的值当执行时会复制一次,无论其是什么类型都是复制的值\n29、for...range中所有数据值都会被分配到具有唯一地址的变量中。因此，如果每次遍历时都存储指向该变量的指针，就会陷入“同一指针指向同一元素”的循环陷阱 ——即始终指向最新元素。解决方法有两种：要么在循环作用域内强制创建局部变量，要么通过索引创建指向切片元素的指针。\n30、map进行迭代和插入都是无序的，无法保证顺序。\n假设对一个map插入abcde,迭代出abced cedba都是可能的 31、不要在循环中使用defer，它会将语句在函数返回之后再执行。如果一定要在循环中使用defer可以在循环中调用一个函数比如闭包\n32、go中string底层引用的是一个不能修改byte切片,字符串使用len返回的是字节数而不实字符数，如果想要返回字符串需要将string转为rune 统计字符数可以使用utf8.RuneCountInString\ns := \u0026#34;hello\u0026#34; fmt.Println(len(s)) // 5 s := \u0026#34;汉\u0026#34; fmt.Println(len(s)) // 3 33、go的源码都采用utf-8进行编码\n34、若要遍历字符串中的rune，可以直接使用字符串的范围循环。但需注意，这里的索引并非rune本身的索引，而是底层字节序列的起始位置。由于rune可能由多个字节组成，若要访问rune本身，应使用范围循环的值变量而非字符串中的索引。此外，若要获取字符串的第i个符文，在大多数情况下需要将字符串转换为rune切片。\ns:=\u0026#34;adbcd\u0026#34; r:= []rune(s) // 获取字符串长度 utf8.RuneCountInString(s) 34、TrimRight或TrimLeft函数会逐个回溯遍历字符串中的每个字符。若某个字符属于给定集合，则被移除；否则终止遍历并返回剩余字符串。因此本示例返回123。\nfmt.Println(strings.TrimRight(\u0026#34;123oxo\u0026#34;, \u0026#34;xo\u0026#34;)) // 123 fmt.Println(strings.TrimLeft(\u0026#34;oxo123\u0026#34;, \u0026#34;ox\u0026#34;)) // 123 fmt.Println(strings.TrimPrefix(\u0026#34;oxo123\u0026#34;, \u0026#34;ox\u0026#34;)) /// o123 35、go中字符串是不可变的如果需要进行多个字符串拼接使用strings.Builder，若已知未来字符串的字节数，应使用Grow方法预先分配内部字节切片\nfunc concat(values []string) string { total := 0 for i := 0; i \u0026lt; len(values); i++ { total += len(values[i]) // 统计每个字符串的字节数 } sb := strings.Builder{} // 底层是持有一个byte切片,WriteString执行后都会对这个切片进行追加操作 // Grow 给builder持有的切片指定多少字节数，减少字节切片扩容操作，提升性能 sb.Grow(total) // 根据统计的字节数给builder开辟空间，减少内存分配 for _, value := range values { _, _ = sb.WriteString(value) } return sb.String() } 36、大多数输入输出操作都是用[]byte而不是字符串来完成的。当我们纠结该用字符串还是[]byte时，不妨回想一下：使用[]byte其实并不一定不方便。事实上，字符串包里所有导出的函数在bytes包里都有对应版本，比如Split、Count、Contains、Index等等。因此，无论是否进行I/O操作，我们都应该先考虑是否可以用bytes替代字符串来实现整个工作流程，从而避免额外转换带来的麻烦。\n37、字符串需要记住 1.len返回的是字节数而不实字符串 2.对字符串进行切割子串操作可能会产生内存泄漏(log[:5]),从go 1.18开始创建一个字符串的子串可以使用strings.Clone\n38、方法接收器\n必须为指针\n1.若方法需要对接收者进行类型转换。当接收者为切片且方法需要追加元素时，该规则同样适用。\n2.若方法接收方包含不可复制的字段（例如sync包的类型部分），我们将在错误#74《复制同步类型》中详细讨论该问题。\ntype slice []int func (s *slice) add(element int) { *s = append(*s, element) } 应该为指针 若接收方为大型对象，使用指针可提升调用效率，因其能避免进行大规模数据复制。当难以界定‘大型’的具体范围时，基准测试可作为解决方案；由于其受多重因素影响，几乎无法给出确切的尺寸标准。\n必须为值类型\n1.如果必须强制接收方不可变性。 2.如果接收方是映射、函数或通道。否则将发生编译错误。\n应该为值类型\n1.如果接收者是一个不需要修改的切片。 2.如果接收者是一个小型数组或结构体，其本身是值类型且没有可变字段，例如时间。\n3.如果接收者是基本类型，如int、float64或string。\n39、函数使用命令返回值时，默认会初始化的为该类型的初始值\n40、在大多数情况下，将文件名作为函数参数来读取文件内容应被视为一种代码异味（特定函数如os.Open除外）。可以使用io.Reader作为参数\nfunc countEmptyLines(reader io.Reader) (int, error) { scanner := bufio.NewScanner(reader) for scanner.Scan() { // ... } } 41.使用defer调用函数时，参数为立刻进行赋值。简而言之，调用函数或方法的defer操作时，其参数会立即执行。若需在后续修改传入的参数，可使用指针或闭包实现。\ns := \u0026#34;abc\u0026#34; defer f(s) // s = abc defer f(){ fmt.Println(s) // s = ddd 闭包调用执行时才赋值 }() s = \u0026#34;ddd\u0026#34; func main() { i := 0 j := 0 defer func(i int) { fmt.Println(i, j) }(i) i++ j++ // i = 0 // j = 1 } 42.在处理错误时，我们可以选择进行错误包装。包装是指为错误添加额外上下文信息和/或将错误标记为特定类型。如果需要对错误进行标记，则应创建自定义错误类型。然而，若只需添加额外上下文，就应使用带有%w指令的fmt.Errorf，因为这无需创建新的错误类型。但需注意，错误包装可能产生耦合性，因为它会使调用方能够访问原始错误。若要避免这种情况，就不应使用错误包装，而应采用错误转换，例如使用带有%v指令的fmt.Errorf。\n// 错误包装 if err != nil { return fmt.Errorf(\u0026#34;bar failed: %w\u0026#34;, err) } 43.如果我们依赖Go 1.13的错误包装机制，就必须使用errors.As来检查某个错误是否属于特定类型。这样一来，无论错误是由被调用函数直接返回，还是被包装在另一个错误中，errors.As都能递归解包主错误，并判断其中是否存在符合特定类型的错误。\n44.若在应用程序中使用错误包裹功能（通过%w指令和fmt错误函数），则应使用errors.Is而非==来检查错误是否与特定值匹配。因此，即使哨兵错误被包裹，errors.Is仍能递归解包，并将链中的每个错误与指定值进行比对。\n45.错误处理应当只执行一次。正如我们所见，记录错误本质上就是处理错误。因此，我们应当选择记录错误或返回错误。这样做既能简化代码，又能更深入地理解错误情况。使用错误包装是最便捷的方法，它既能传递源错误，又能为错误添加上下文信息。\n46.当想要忽略一个err时，使用_占位更能传达出明显的有效信息,表示忽略处理这个错误\n并发 47.并发是指同时处理多项任务。并行是指同时执行多项任务。\n48.在开发并发应用程序时，必须明确区分数据竞争与竞争条件。当多个goroutine同时访问同一内存地址且至少有一个在写入时，就会发生数据竞争。这种现象会导致程序出现异常行为。但需要注意的是，无数据竞争的应用程序并不意味着结果绝对确定。即使程序没有数据竞争，仍可能因goroutine执行速度、消息发布到通道的时效性、数据库调用耗时等不可控因素产生波动——这正是竞争条件的表现。准确理解这两个概念，是掌握并发应用设计精髓的关键所在。\n49.如果传输context不确定时使用context.TODO()，context必须要保证一直存在直到函数返回\n50.创建一个go程必须清楚的知道它什么时候执行关闭,必须一直占用资源\n51.在使用带多个通道的select语句时，必须注意：当多个选项同时就绪时，源码中的第一个case不会自动胜出。Go会随机挑选可执行的case，因此无法保证具体选中哪个选项。针对单个生产者协程的情况，可通过无缓冲通道或单一通道解决此问题；而对于多个生产者协程的场景，则可通过嵌套select配合default子句来实现优先级处理。\n52.通道可以携带数据或不携带数据。若希望按照Go语言惯例设计符合习惯的API，需注意：不携带数据的通道应声明为chan struct{}类型。这种设计能向接收方明确传达：消息本身不包含任何有意义的内容，其价值仅在于传递\u0026quot;已接收到信号\u0026quot;这一事实。在Go语言中，此类通道被称为通知通道。\n53.总结来说，等待一个nil通道或向nil通道发送数据会导致阻塞，而这一特性并非无用。正如我们在合并两个通道的示例中所见，可以利用nil通道来实现一种精巧的状态机，从而动态地从select语句中移除其中一个分支。让我们记住这个思路：nil通道在特定场景下非常有用，应成为Go开发者在处理并发代码时的工具之一。\n// 示例：使用nil通道动态管理select分支 for { select { case v, ok := \u0026lt;-ch1: if !ok { ch1 = nil // 将通道置为nil，使此case不再被选中 continue } process(v) case v, ok := \u0026lt;-ch2: if !ok { ch2 = nil // 将通道置为nil，使此case不再被选中 continue } process(v) } if ch1 == nil \u0026amp;\u0026amp; ch2 == nil { break // 两个通道都已关闭，退出循环 } } 54.在并发中使用字符串格式化可能会导致数据竞争与死锁\nfunc potentialDeadlock() { var mu sync.Mutex mu.Lock() // 危险：如果format内部触发了需要同一锁的操作 s := fmt.Sprintf(\u0026#34;Locked: %v\u0026#34;, someFunction()) mu.Unlock() } func someFunction() string { // 如果这里也需要获取同一个锁，就会死锁 mu.Lock() // 第二次尝试加锁 - 死锁！ defer mu.Unlock() return \u0026#34;data\u0026#34; } //// 数据竞争 var sharedData string func goroutine1() { // 不安全：同时修改共享数据 sharedData = fmt.Sprintf(\u0026#34;Value: %d\u0026#34;, time.Now().Unix()) } func goroutine2() { // 同时读取或修改 sharedData fmt.Println(sharedData) } 55.在并发环境中处理切片时，我们必须记住，对切片使用 append 操作并不总是无竞态的。根据切片的状态以及它是否已满，行为会发生变化。如果切片已满，append 操作是无竞态的。否则，多个 goroutine 可能会竞争更新同一个数组索引，从而导致数据竞态。\ns := make([]int, 1) // 无数据竟态,当一个go程插入后，切片已满底层会重新创建一个数组扩容 s := make([]int, 0, 1) // 存在数据竟态,两个go程都访问索引为 1 的位置 go func() { s1 := append(s, 1) fmt.Println(s1) }() go func() { s2 := append(s, 1) fmt.Println(s2) }() 56.当需要触发多个goroutine并处理错误及上下文传递时，可考虑errgroup是否为一种解决方案。\nfunc handler(ctx context.Context, circles []Circle) ([]Result, error) { results := make([]Result, len(circles)) g, ctx := errgroup.WithContext(ctx) for i, circle := range circles { i := i circle := circle g.Go(func() error { result, err := foo(ctx, circle) if err != nil { return err } results[i] = result return nil }) } if err := g.Wait(); err != nil { // g.Wait() 等待所有go程执行完成 return nil, err } return results, nil } 57.使用sync包时，任何时候不要使用复制值。当多个goroutine需要访问同一同步元素时，必须确保它们都依赖于同一实例。该规则适用于同步包中定义的所有类型。使用指针是解决此问题的方法：我们可以使用指向同步元素的指针，或指向包含同步元素的结构体的指针。\n// 都不能被复制 sync.Cond sync.Map sync.Mutex sync.RWMutex sync.Once sync.Pool sync.WaitGroup 在以下情况下，我们可能会遇到意外复制sync字段的问题：\n调用具有值接收器的方法（如前所述） 调用接收sync类型参数的函数 调用接收包含sync字段的结构体参数的函数 58.通常使用time.After方法时需谨慎。需注意资源仅在计时器到期后才会释放。若在循环、Kafka消费者函数或HTTP处理程序中重复调用time.After，可能导致内存消耗激增。此时应优先选用time.NewTimer。\nfunc consumer(ch \u0026lt;-chan Event) { timerDuration := 1 * time.Hour timer := time.NewTimer(timerDuration) for { timer.Reset(timerDuration) select { case event := \u0026lt;-ch: handle(event) case \u0026lt;-timer.C: log.Println(\u0026#34;warning: no messages received\u0026#34;) } } } 59.我们应当谨慎处理嵌入字段。虽然推广嵌入字段类型的字段和方法有时会带来便利，但也可能引发细微错误，因为这可能导致父结构体在缺乏明确信号的情况下实现接口。\n// json格式化 会有问题 ID字段会被省略 // 执行json.Marshal()后 \u0026#34;2021-05-18T21:15:08.381652+02:00\u0026#34; type Event struct { ID int time.Time // 这样会组合会实现time的所有方法, time.Time实现了json.Marshaler当调用json.Marshal()会调用它已实现的方法 } type Event struct { ID int Time time.Time // 使用 } // 60.反序列化json字符串可以使用map[string]any,需要注意的是使用任何数值类型（无论是否包含小数）时，系统都会将其转换为float64类型。\n数据库 sql.Open方法并不强制建立连接，首个连接可采用延迟建立机制。若需验证配置正确性并确认数据库连接状态，应在调用sql.Open后执行Ping或PingContext方法。 同样重要的是要记住，创建连接池会涉及四个可配置参数，我们可能需要对它们进行自定义。这些参数分别对应 *sql.DB 的四个导出方法：\n1.SetMaxOpenConns：对于生产级应用至关重要。由于默认值是无限制的，我们应通过设置该参数来确保连接数符合底层数据库的实际承载能力。\n2.SetMaxIdleConns：如果应用程序产生大量并发请求，应提高SetMaxIdleConns的默认值（默认为2），否则应用可能会频繁重新建立连接。\n3.SetConnMaxIdleTime：若应用程序可能面临突发请求，设置SetConnMaxIdleTime十分重要(默认无限制)。当应用恢复平稳状态时，我们需要确保已创建的连接最终被释放。\n4.SetConnMaxLifetime：在连接负载均衡数据库服务器等场景下，设置SetConnMaxLifetime会很有帮助(默认无限制)。这能确保应用程序不会过长时间占用单个连接。 预编译语句是许多SQL数据库为执行重复SQL语句而实现的功能。在内部，该SQL语句经过预编译并与提供的数据分离。 // 如果某个sql语句需要重复执行可以使用预编译语句 // 优势是更有效率，更安全 stmt, err := db.Prepare(\u0026#34;SELECT * FROM ORDER WHERE ID = ?\u0026#34;) 处理查询中的空值。字段为指针，或使用SQL的NullXXX类型。sql.NullString sql.NullBool 处理迭代中的行错误使用row.Err func get(ctx context.Context, db *sql.DB, id string) (string, int, error) { // ... for rows.Next() { // ... } if err := rows.Err(); err != nil { return \u0026#34;\u0026#34;, 0, err } return department, age, nil } 62.所有实现io.Closer资源结构在使用完后都需要被关闭，不然可能导致内存泄漏或其他的问题。如HTTP body sql.Rows os.File\ntype Closer interface { Close() error } 63.在生产级应用中，必须避免使用默认的HTTP客户端和服务器。否则，由于缺乏超时机制，甚至存在恶意客户端利用服务器无超时限制的漏洞，可能导致请求无限期卡住。\nclient := \u0026amp;http.Client{ Timeout: 5 * time.Second, // 请求超时等待时间 Transport: \u0026amp;http.Transport{ DialContext: (\u0026amp;net.Dialer{ Timeout: time.Second, // 连接超时等待时间 }).DialContext, TLSHandshakeTimeout: time.Second, // tls握手超时等待时间 ResponseHeaderTimeout: time.Second, // 服务器响应头等待时间 }, } s := \u0026amp;http.Server{ Addr: \u0026#34;:8080\u0026#34;, ReadHeaderTimeout: 500 * time.Millisecond, // 读取请求头等待超时 ReadTimeout: 500 * time.Millisecond, // 读取请求超时 Handler: http.TimeoutHandler(handler, time.Second, \u0026#34;foo\u0026#34;), // 一个封装函数，用于指定处理程序完成的最大时间 } 测试 给测试文件添加标识区分\n1.添加标识 //go:build integration 2.使用短测试 testing.Short()\n3.使用环境变量标记 //go:build integration package db import ( \u0026#34;testing\u0026#34; ) func TestInsert(t *testing.T) { // ... } // $ go test --tags=integration -v . //go:build !integration 使用了!\n若使用integration标签运行go test，则仅执行集成测试。 若不使用该标签运行go test，则仅执行单元测试。\n一种测试分类方法涉及运行速度。我们需要区分短时运行测试与长时运行测试。举例来说，假设我们有一组单元测试，其中某个测试运行速度极慢。我们希望对这个慢速测试进行分类，避免每次运行（特别是当触发条件是文件保存后时）。短时运行模式使我们能够实现这种区分 func TestLongRunning(t *testing.T) { if testing.Short() { t.Skip(\u0026#34;skipping long-running test\u0026#34;) } // ... } 我们应当牢记：对于使用并发的应用程序，强烈建议（甚至必须）在运行时启用-race参数。该参数可激活数据竞争检测器，通过代码监控来捕捉潜在的数据竞争。 go test -race ./... 当使用t. Parallel标记测试时，该测试会与所有其他并行测试同时执行。但在执行流程中，Go会先逐一运行所有顺序测试，待顺序测试完成后，再执行并行测试。 // 先执行C 再并行执行 AB func TestA(t *testing.T) { t.Parallel() // ... } func TestB(t *testing.T) { t.Parallel() // ... } func TestC(t *testing.T) { // ... } 表格驱动测试是一种高效编写精简测试的技巧。若多个单元测试具有相似结构，可采用表格驱动测试实现互化。该技术通过避免重复，简化了测试逻辑的修改，并便于新增用例。 func TestFoo(t *testing.T) { t.Run(\u0026#34;subtest 1\u0026#34;, func(t *testing.T) { if false { t.Error() } }) t.Run(\u0026#34;subtest 2\u0026#34;, func(t *testing.T) { if 2 != 2 { t.Error() } }) } httptest软件包（https://pkg.go.dev/net/http/httptest）为HTTP测试提供客户端和服务器端的工具 // 模拟请求 req := httptest.NewRequest(http.MethodGet, \u0026#34;http://localhost\u0026#34;, strings.NewReader(\u0026#34;foo\u0026#34;)) // 模拟服务器 srv := httptest.NewServer( http.HandlerFunc( func(w http.ResponseWriter, r *http.Request) { _, _ = w.Write([]byte(`{\u0026#34;duration\u0026#34;: 314}`)) }, ), ) defer srv.Close() iotest软件包（https://pkg.go.dev/testing/iotest）提供了测试读写器的实用工具。这个便捷的工具包常被Go开发者忽视。 func TestLowerCaseReader(t *testing.T) { err := iotest.TestReader( \u0026amp;LowerCaseReader{reader: strings.NewReader(\u0026#34;aBcDeFgHiJ\u0026#34;)}, []byte(\u0026#34;acegi\u0026#34;), ) if err != nil { t.Fatal(err) } } 查看测试覆盖率 $ go test -coverprofile=coverage.out ./... $ go tool cover -html=coverage.out 测试环境准备，在测试前准备资源，在测试后关闭资源 // 测试前setup func TestMySQLIntegration(t *testing.T) { // ... db := createConnection(t, \u0026#34;tcp(localhost:3306)/db\u0026#34;) // ... } func createConnection(t *testing.T, dsn string) *sql.DB { db, err := sql.Open(\u0026#34;mysql\u0026#34;, dsn) if err != nil { t.FailNow() } t.Cleanup( // 测试完后关闭资源 func() { _ = db.Close() }) return db } 该特定函数接受一个*testing.M参数，该参数通过暴露单一的Run方法来执行所有测试。 func TestMain(m *testing.M) { setupMySQL() code := m.Run() teardownMySQL() os.Exit(code) } 内存优化 64.设计结构体时如何减少内存分配量？经验法则是对结构体进行重组，使其字段按类型大小降序排列。在本案例中，int64类型排在首位，随后是两个字节类型：\n// 由于结构体的大小必须是字长（8字节）的整数倍，因此其地址总长度为24字节而非17字节。编译时，Go编译器会添加填充数据以确保数据对齐 type Foo struct { i int64 b1 byte // 在64位的系统编译器默认会补 7个byte b2 byte } 设计结构图需注意数据对齐问题。将Go结构体的字段按大小降序排列可避免填充。防止填充意味着分配更紧凑的结构体，这可能带来诸如减少垃圾回收频率和提升空间局部性等优化效果。\n65.若编译器无法确认变量在函数返回后未被引用，则该变量将被分配到堆内存中。\n函数或方法返回指针，变量会逃逸到堆中 66.编译优化\nmap优化 // 这个版本要快些，编译器会避免将bytes转为string func (c *cache) get(bytes []byte) (v int, contains bool) { v, contains = c.m[string(bytes)] return } func (c *cache) get(bytes []byte) (v int, contains bool) { key := string(bytes) v, contains = c.m[key] return } sync.pool\n当我们需要频繁创建大量同一类型的对象时，可以考虑使用sync.Pool。作为一组可复用的临时对象存储池，它能有效避免同类数据的重复内存分配，并且支持多个goroutine安全并发访问。 // 需要创建多个byte切片的场景使用sync.pool优化 var pool = sync.Pool{ New: func() any { return make([]byte, 1024) }, } func write(w io.Writer) { buffer := pool.Get().([]byte) buffer = buffer[:0]// 清空buffer defer pool.Put(buffer) getResponse(buffer) _, _ = w.Write(buffer) } 67.使用pprof检测\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;\u0026#34;) }) log.Fatal(http.ListenAndServe(\u0026#34;:80\u0026#34;, nil)) } 68.io.Discard 是 Go 语言中处理 \u0026ldquo;我不关心这些数据\u0026rdquo; 场景的优雅解决方案，它让代码更清晰、更高效。\n与linuxe中/dev/null相似 io.Discard内部不执行任何操作，不占用内存，只有函数调用开销 func downloadData(w io.Writer) error { // 模拟下载数据并写入 w _, err := w.Write([]byte(\u0026#34;下载的数据...\u0026#34;)) return err } func main() { // 我们只需要知道下载是否成功，不关心数据内容 err := downloadData(io.Discard) if err != nil { fmt.Println(\u0026#34;下载失败:\u0026#34;, err) } else { fmt.Println(\u0026#34;下载成功\u0026#34;) } } ","date":"2026-01-05T00:00:00Z","permalink":"https://wushengyouya.github.io/p/100gomistakes/","title":"100GoMistakes"},{"content":"\n随记 今天是2025的最后一天，外面下着大雨，下班回来的路上鞋被雨水淋湿，冰冷的脚让我加快了回家的步伐。\n今年家里突然想给我买房，从目前家里财务状况来看，其实购房的压力很大，不仅对我还是对家里。\n今年玩了很长时间的永劫无间确实是一款优秀的游戏，有一段时间上瘾了每天下班回来就玩。\n今年英雄联盟新出的模式“符文大乱斗”很好玩，玩了很多次。\n今年花了2000左右买衣服穿，似乎是这多年中花钱买衣服最多的一年。\n完成的事情 能阅读英文书籍 阅读英文技术书籍 100 Go Mistakes And How to avoid Them 看完走遍美国英语教学视频 学会了一首粤语歌-我们的天空 2025是刀剑神域的时间与现实重叠的一年，重新看了一遍刀剑。 来年规划 能使用英语日常交流 无障碍阅读英语技术文档 番剧年鉴 2025只看完了9部番剧，比起往年少了很多，可能花了时间去打游戏去了。\n今年我的年度动画是-末日后酒店。\n今年有趣的视频 ","date":"2025-12-31T00:00:00Z","image":"https://wushengyouya.github.io/p/2025%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/image-9.png","permalink":"https://wushengyouya.github.io/p/2025%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","title":"2025年度总结"},{"content":"mongodb MongoDB是一种文档型数据库，它是为存储和检索大量数据而设计的。\nuse 名字,创建数据数据库，默认回先存放在内存中，如果有集合了才会创建到磁盘\n使用场景 高并发 高效率存储（高性能） 高扩展和高可用 适用的数据结构 非结构化数据 文档数据 地图数据 聊天数据 日志数据 缓存数据 操作 网上优秀的参考:\nhttps://gist.github.com/dollarkillerx/ecd4bdf66737175c78d9d0bc1643c1c0 https://wiki.eryajf.net/pages/7fea3f/#%E6%B7%BB%E5%8A%A0%E5%A4%9A%E6%9D%A1 官方文档 数据库连接 // bson.D 有序 表示文档 排序、投影、更新 // bson.M 无序 map集合 查询、查询 // bson.E 键值对，可以用来构建bson.M // bson.A 有序 表示数组 func InitDb() *mongo.Client { uri := \u0026#34;mongodb://127.0.0.1:27017\u0026#34; //连接数据库 client, err := mongo.Connect(context.Background(), options.Client().ApplyURI(uri)) if err != nil { log.Fatal(\u0026#34;client:\u0026#34;, err) } // 判断服务是不是可用 if err = client.Ping(context.Background(), readpref.Primary()); err != nil { log.Fatal(\u0026#34;ping:\u0026#34;, err) } /* 关闭连接 defer func() { if err = client.Disconnect(context.TODO()); err != nil { log.Fatal(\u0026#34;dis:\u0026#34;, err) } }() */ return client } 插入单条 func AddOne() { ctx := context.Background() //当数据库或者集合不存在时，会自动创建数据库与集合 db := InitDb().Database(\u0026#34;class\u0026#34;) defer db.Client().Disconnect(ctx) table := db.Collection(\u0026#34;user\u0026#34;) doc := make(map[string]interface{}) doc[\u0026#34;id\u0026#34;] = 2 doc[\u0026#34;name\u0026#34;] = \u0026#34;mikasa2\u0026#34; //doc1 := bson.A{\u0026#34;bar\u0026#34;, \u0026#34;world\u0026#34;, 3.14159, bson.D{{\u0026#34;qux\u0026#34;, 12345}}} _, err := table.InsertOne(ctx, doc) if err != nil { log.Fatal(\u0026#34;插入失败:\u0026#34;, err) } if err != nil { log.Fatal(err) } } 插入多条 func AddMore() { ctx := context.Background() db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;user\u0026#34;) var doc = []interface{}{ bson.D{{Key: \u0026#34;title\u0026#34;, Value: \u0026#34;title1\u0026#34;}, {Key: \u0026#34;text\u0026#34;, Value: \u0026#34;text1\u0026#34;}}, bson.D{{Key: \u0026#34;title\u0026#34;, Value: \u0026#34;title2\u0026#34;}, {Key: \u0026#34;text\u0026#34;, Value: \u0026#34;text2\u0026#34;}}, } r, err := table.InsertMany(ctx, doc) if err != nil { log.Fatal(err) } fmt.Println(r) } 更新一条 func UpdateOne() { db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;user\u0026#34;) filter := bson.M{\u0026#34;title\u0026#34;: \u0026#34;你好\u0026#34;} update := bson.D{{Key: \u0026#34;$set\u0026#34;, Value: bson.D{{Key: \u0026#34;title\u0026#34;, Value: \u0026#34;你好美女\u0026#34;}}}} //三个参数 context filter要筛选的数据 update 要更新的数据 r, err := table.UpdateOne(context.Background(), filter, update) if err != nil { log.Fatal(err) } fmt.Println(r) } 更新多条 func UpdateMany() { db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;testdata\u0026#34;) filter := bson.D{{Key: \u0026#34;group_identify\u0026#34;, Value: \u0026#34;test\u0026#34;}} //$mul 更新操作符,将age这列乘以2, $set 也是更新数据,重新给一个值 update := bson.D{{Key: \u0026#34;$mul\u0026#34;, Value: bson.D{{Key: \u0026#34;age\u0026#34;, Value: 2}}}} r, err := table.UpdateMany(context.Background(), filter, update) if err != nil { log.Fatal(err) } fmt.Println(r) } 查询单条 // 查询单条 func FindOne() { db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;testdata\u0026#34;) var result bson.M err := table.FindOne(context.Background(), bson.M{\u0026#34;name\u0026#34;: \u0026#34;小A\u0026#34;}).Decode(\u0026amp;result) if err != nil { log.Fatal(err) } //序列化成json Encode 返回 val 的 JSON 编码 v, err := encoder.Encode(result, encoder.SortMapKeys) if err != nil { log.Fatal(err) } fmt.Println(string(v)) //利用id查询 var result1 bson.M //用十六进制创建objectId objid, err := primitive.ObjectIDFromHex(\u0026#34;65990f180b9dae893a119618\u0026#34;) if err != nil { log.Fatal(err) } table.FindOne(context.Background(), bson.M{\u0026#34;_id\u0026#34;: objid}).Decode(\u0026amp;result1) v1, err := encoder.Encode(result1, encoder.SortMapKeys) if err != nil { log.Fatal(err) } fmt.Println(string(v1)) } 用正则模糊查询 type Article struct { Title string Text string } // 模糊查询 func FindAdLike() { db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;user\u0026#34;) findOptions := options.Find() filter := bson.D{} filter = append(filter, bson.E{ Key: \u0026#34;title\u0026#34;, Value: bson.M{\u0026#34;$regex\u0026#34;: primitive.Regex{Pattern: \u0026#34;.*\u0026#34; + \u0026#34;i\u0026#34; + \u0026#34;.\u0026#34;, Options: \u0026#34;i\u0026#34;}}, //正则表达式模糊查询 i表示忽略大小写 }) cus, err := table.Find(context.TODO(), filter, findOptions) //关闭游标 defer func(cus *mongo.Cursor, ctx context.Context) { err := cus.Close(ctx) if err != nil { return } }(cus, context.TODO()) if err != nil { log.Fatal(err) } list := make([]*Article, 0) for cus.Next(context.TODO()) { article := new(Article) err := cus.Decode(\u0026amp;article) if err != nil { log.Fatal(\u0026#34;decode failed:\u0026#34;, err) } list = append(list, article) } fmt.Println(len(list)) } 查询多条 func FindMany() { ctx := context.Background() db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;testdata\u0026#34;) cus, err := table.Find(ctx, bson.M{}) //关闭游标 defer func() { if err := cus.Close(ctx); err != nil { log.Fatal(err) } }() if err != nil { log.Fatal(err) } //第一种查询方法 var list []bson.M err = cus.All(ctx, \u0026amp;list) if err != nil { log.Fatal(err) } fmt.Println(len(list)) for _, v := range list { temp, err := encoder.Encode(v, encoder.SortMapKeys) //转为Json字符串 if err != nil { log.Fatal(err) } fmt.Println(string(temp)) } //第二种 cus1, err := table.Find(ctx, bson.M{}) if err != nil { log.Fatal(err) } var list1 []bson.M for cus1.Next(ctx) { var t bson.M err := cus1.Decode(\u0026amp;t) if err != nil { log.Fatal(err) } list1 = append(list1, t) } fmt.Println(list1) } 获取总数 func GetAllCount() { db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;testdata\u0026#34;) count, err := table.CountDocuments(context.Background(), bson.D{}) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;总条数为：\u0026#34;, count) } 替换一条 func ReplaceOne() { db := InitDb().Database(\u0026#34;class\u0026#34;) table := db.Collection(\u0026#34;testdata\u0026#34;) filter := bson.M{\u0026#34;name\u0026#34;: \u0026#34;大F\u0026#34;} replace := bson.D{{\u0026#34;name\u0026#34;, \u0026#34;大大F\u0026#34;}, {\u0026#34;identify\u0026#34;, \u0026#34;fff\u0026#34;}, {\u0026#34;age\u0026#34;, 100}, {\u0026#34;group_identify\u0026#34;, \u0026#34;test\u0026#34;}} result, err := table.ReplaceOne(context.Background(), filter, replace) if err != nil { log.Fatal(err) } fmt.Println(result) } 删除单条 func DeleteOne() { table := InitDb().Database(\u0026#34;class\u0026#34;).Collection(\u0026#34;testdata\u0026#34;) filter := bson.M{\u0026#34;name\u0026#34;: \u0026#34;大大F\u0026#34;} r, err := table.DeleteOne(context.Background(), filter) if err != nil { log.Fatal(err) } fmt.Println(r) } 删除多条 func DeleteMany() { table := InitDb().Database(\u0026#34;class\u0026#34;).Collection(\u0026#34;testdata\u0026#34;) //有序 在一些特殊情况下，比如确保键值对的顺序对于查询的匹配是重要的 //filter := bson.D{{Key: \u0026#34;age\u0026#34;, Value: bson.D{{Key: \u0026#34;$gt\u0026#34;, Value: 3}}}}//同样可以查 filter := bson.M{\u0026#34;age\u0026#34;: bson.M{\u0026#34;$gte\u0026#34;: 5}} //无序 r, err := table.DeleteMany(context.Background(), filter) if err != nil { log.Fatal(err) } fmt.Println(r) } 汇总 func Count() { coll := InitDb().Database(\u0026#34;class\u0026#34;).Collection(\u0026#34;testdata\u0026#34;) filter := bson.D{{\u0026#34;group_identify\u0026#34;, \u0026#34;test\u0026#34;}} //EstimatedDocumentCount() 获得集合中 文档数量的近似值 estCount, estCountErr := coll.EstimatedDocumentCount(context.TODO()) if estCountErr != nil { panic(estCountErr) } //获得集合中 文档的确切数量 count, err := coll.CountDocuments(context.TODO(), filter) if err != nil { panic(err) } fmt.Println(estCount, count) } 添加字段 func UpdateOneField() { table := InitDb().Database(\u0026#34;class\u0026#34;).Collection(\u0026#34;testdata\u0026#34;) objid, err := primitive.ObjectIDFromHex(\u0026#34;659955050b9dae893a11961c\u0026#34;) if err != nil { log.Fatal(err) } filter := bson.M{\u0026#34;_id\u0026#34;: objid} //添加字段 $push $push有一个问题就是，如果一个值重复往一个数组里添加 $addToSet数据重复不会再添加 updateData := bson.M{\u0026#34;$addToSet\u0026#34;: bson.M{\u0026#34;link_data\u0026#34;: bson.M{\u0026#34;field_identify\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;model_data_id\u0026#34;: \u0026#34;5\u0026#34;}}} r, err := table.UpdateOne(context.TODO(), filter, updateData) if err != nil { log.Fatal(err) } fmt.Println(r) } 删除一个字段中的数据 func DeleteOneFieldData() { table := InitDb().Database(\u0026#34;class\u0026#34;).Collection(\u0026#34;testdata\u0026#34;) objid, err := primitive.ObjectIDFromHex(\u0026#34;659955050b9dae893a11961c\u0026#34;) if err != nil { log.Fatal(err) } filter := bson.M{\u0026#34;_id\u0026#34;: objid} updateData := bson.M{\u0026#34;$pull\u0026#34;: bson.M{\u0026#34;link_data\u0026#34;: bson.M{\u0026#34;field_identify\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;model_data_id\u0026#34;: \u0026#34;5\u0026#34;}}} r, err := table.UpdateOne(context.Background(), filter, updateData) if err != nil { log.Fatal(err) } fmt.Println(r) } 删除字段和数据 func DeleteOneField() { table := InitDb().Database(\u0026#34;class\u0026#34;).Collection(\u0026#34;testdata\u0026#34;) objid, err := primitive.ObjectIDFromHex(\u0026#34;659955050b9dae893a11961c\u0026#34;) if err != nil { log.Fatal(err) } filter := bson.M{\u0026#34;_id\u0026#34;: objid} updateData := bson.M{\u0026#34;$unset\u0026#34;: bson.M{\u0026#34;link_data\u0026#34;: \u0026#34;\u0026#34;}} r, err := table.UpdateOne(context.Background(), filter, updateData) if err != nil { log.Fatal(err) } fmt.Println(r) } ","date":"2025-03-26T00:00:00Z","image":"https://wushengyouya.github.io/image.png","permalink":"https://wushengyouya.github.io/p/mongodb%E5%AD%A6%E4%B9%A0/","title":"mongodb学习"},{"content":"负数转为uint256 在solidity中将一个负数强制转为uint256时,solidity会直接将其二进制补码解释为一个无符号整数\n例如：-1 的二进制补码是全 1，转为uint256后会变成2^256-1 将负数-0.008396714242162444 ether,转为uint256会得到下面这个非常大的数,实际上是2^256 - 0.008396714242162444 ether 的结果 115792089237316195423570985008687907853269984665640564039457584007913129639935 int256 negative_1 = -1; int256 negative_2 = -0.008396714242162444 ether; uint256 a = uint256(negative_1); uint256 b = uint256(negative_2); ","date":"2025-01-07T00:00:00Z","permalink":"https://wushengyouya.github.io/p/solidity%E5%BC%82%E5%B8%B8%E8%AE%B0%E5%BD%95/","title":"solidity异常记录"},{"content":"智能合约审计 Foundry Fuzzing = Stateless fuzzing\nFoundry Invariant = Stateful fuzzing\n有状态模糊测试(Foundry Invariant) 在多次测试运行之间保持合同状态 允许在一系列操作中测试复杂场景 适用于检查跨多个操作应该始终保持不变的属性 需要更多的设置，但可以发现更深层次的问题 无状态模糊测试(Foundry fuzzing) 每次测试运行都会创建一个新的合约实例 不保留任何状态 适用于单独测试各个函数 不变性测试 确定不变量 不变性是应该在模糊测试活动期间始终成立的条件表达式。\n对于Uniswap,x*y=k 公式始终成立 对于ERC-20代币，所有用户的余额等于 totalSupply()总供应量 模糊测试 // SPDX-License-Identifier: MIT pragma solidity ^0.8.23; import \u0026#34;@thirdweb-dev/contracts/base/ERC721Drop.sol\u0026#34;; contract NFTDrop is ERC721Drop { constructor( string memory _name, string memory _symbol, address _royaltyRecipient, uint128 _royaltyBps, address _primarySaleRecipient ) ERC721Drop( _name, _symbol, _royaltyRecipient, _royaltyBps, _primarySaleRecipient ) {} function mint(address _to, uint256 _amount) external { require(_amount \u0026gt; 0, \u0026#34;You must mint at least one token!\u0026#34;); _safeMint(_to, _amount); } } /************************************************************/ // SPDX-License-Identifier: MIT pragma solidity ^0.8.23; import \u0026#34;forge-std/Test.sol\u0026#34;; import \u0026#34;./NFTDrop.sol\u0026#34;; contract NFTDropTest is Test { NFTDrop drop; address testAddr; function setUp() public { drop = new NFTDrop(\u0026#34;TestToken\u0026#34;, \u0026#34;TEST\u0026#34;, address(this), 0, address(this)); testAddr = address(this); } function testMint(uint16 amount) public { vm.expectRevert(\u0026#34;You must mint at least one token!\u0026#34;); drop.mint(testAddr, amount); assertEq(drop.balanceOf(testAddr), amount); } } The Rekt Test Do you have all actors,roles,and privileges documented? Do you keep documentation of all the external services,contracts,and oracles you rely on? Do you have a written and tested incident response plan？ Do you document the best ways to attack your system? Do you perform identity verification and backgroud checks on all employees? Do you have a team member with security defined in their role? Do you require hardware security keys for production systems? Does your key management system require multiple humans and physical steps? Do you define key invariants for your system and test them on every commit? Do you use the best automated tools to discover security issues in you code? Do you undergo external audits and maintain a vulnerability disclosure or bug bounty program? Have you considerd and mitigated avenues for abusing users of you system? ","date":"2024-09-12T00:00:00Z","permalink":"https://wushengyouya.github.io/p/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%AE%A1%E8%AE%A1/","title":"智能合约审计"},{"content":"\n","date":"2024-07-11T00:00:00Z","image":"https://wushengyouya.github.io/p/uniswap/image.png","permalink":"https://wushengyouya.github.io/p/uniswap/","title":"Uniswap"},{"content":"Foundry 什么是Foundry Foundry是一个solidity框架，用于构建、测试、模糊、调试和部署智能合 约。Foundry完全使用Solidity进行开发与测试，而且构建、测试的执行速 非常快。\nFoundry通过cheatcodes来操纵区块链的状态，可以方便我们模拟各种情况。\nFoundry用Rust语言编写，包含了一系列可以与Ethereum网络交互的工具\nForge 用来进行合约的测试 Cast 与合约进行交互，发交易，查询链上数据 Anvil 可以模拟一个私有节点 Chisel 可以在命令行快速的有效的实时的写合约、测试合约 安装Foundry 使用Foundryup安装 Foundryup是foundry工具包的安装器\n1、终端执行，这会下载foundryup.（提示设置环境变量或者新开窗口，并通过运行它安装foundry）\ncurl -L https://foundry.paradigm.xyz | bash 2、执行后会自动安装,forge,cast,anvil,chisel\n3、验证安装是否成功\nforge --version Windows一般采用git bash内执行安装,因为目前Foundryup不支持Powershell\n私钥的存储方式 测试阶段可以使用键值对$PRIVATE_KEY存放在.env文件中,并保证.env文件包含在.gitignore中 涉及到真实货币时可以采用--interactive 方式或者使用 keystore file protected by a password 使用 thirdweb部署 forge script --help # 指定一个加密文件存储路径，该文件由密码加密，这样私钥不会明文显示 forge script --keystore \u0026lt;PATH\u0026gt; # 使用私钥导入钱包 cast wallet import \u0026lt;NAME\u0026gt; --interactive cast wallet list forge script script/DeploySimpleStorage.s.sol:DeploySimpleStorage --rpc-url 127.0.0.1:8545 --account defaultkey --sender 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266 --broadcast -vvvv 交易 交易费计算 Total Cost = Gas Used * Gas Price\n279,288.255846978 Gwei = 357,498 * 0.781230261 Gwei =\u0026gt; 0.000279288255846978 ETH 例子\nEVM和zksync交易类型 以太坊虚拟机（EVM）和ZKsync生态系统支持多种交易类型，以适应各种以太坊改提案(EIP)。最初，以太坊只有一种交易类型(0x0)， 但随着生态系统演变，通过各种EIP引入了多种类型。\nLegacy 0x0：evm最初的交易类型 EIP-2930 0x1： EIP-1559 0x2：当前EVM的默认类型。在以太坊伦敦升级中引入，EIP-1559：ETH 1.0 链费用市场变更，修改了交易费用的处理方式，用基础费用替换了 gasPrice ，并允许用户设置 maxPriorityFeePerGas 和 maxFeePerGas 。 EIP-712 0x71：类型化结构化数据哈希和签名，允许在交易中实现结构化数据的哈希和签名。ZKsync Era 使用这项技术来实现账户抽象和代付主等功能。 交易类型的区别、legacy、eip-1559、eip-2930、eip-4844\nForge forge init初始化项目 forge init hello_foundry init 命令会自动创建一个项目目录,并安装好forge-std库\nscr:智能合约目录 script:部署脚本文件 lib:依赖库目录 test:智能合约测试用例文件 foundry.toml:配置文件 forge build编译及 forge test测试 forge build编译合约，如果foundry.toml文件未指定solc编译版本，则默认使用最新的。编译好的文件(合约ABI，bytecode)，放在out文件夹中。\nforge test命令执行测试用例，一键把所有test包下的测试用例都执行一边，并打印测试的结果。\n一些约定:\n测试用例位于test包下,通常用***.t.sol为结尾来命名 测试方法的命名test_***，后面遵循骆驼峰命名 继承forge-std标准库下的Test.sol合约来编写测试用例 // SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13; import {Test, console} from \u0026#34;forge-std/Test.sol\u0026#34;; import {Counter} from \u0026#34;../src/Counter.sol\u0026#34;; contract CounterTest is Test { Counter public counter; function setUp() public {//测试前的初始化 counter = new Counter(); counter.setNumber(0); } function test_Increment() public { counter.increment(); assertEq(counter.number(), 1);//断言修改后的状态变量,assertNotEq断言不相等 } function testFuzz_SetNumber(uint256 x) public { counter.setNumber(x); assertEq(counter.number(), x); } } 执行测试的三种方式:\nforge test 一键执行 forge test --match-path test/Counter.t.sol,使用--match-path指定某一路径下的文件 forge test --match-contract ConunterTest --match-test test_Increment,用--match-contract来指定测试合约的名称 验证Revert:\ntestFail_xxx来验证是否触发了revert操作，如果没有触发revert则测试失败，否则测试通过。 vm.expeectRevert(stdError.arithmericError)来期望一个revert 测试函数必须具有 external 或 public 可见性。声明为 internal 或 private 的函数不会被forge处理，即使它们的前缀为 test\n测试等级:\n-v 默认 -vv 打印测试中的日志、断言、预期结果、错误原因 -vvv 打印出测试失败中的失败堆栈调用 -vvvv 显示最详细的测试结果，包括所有内部调用和日志信息 -vvvvv forge create合约部署与验证 forge create --rpc-url https://sepolia.infura.io/v3/37124d613dde4cb4b2f0ebc6d6149277 --private-key 7a53f0a5f517ecb17943179a7eb351227607ee7bb01c2ca9d1785ea4ade5f147 --etherscan-api-key IC4N3ES8HC8CSGCDPUN3JIPGJY5KPPKZFN --verify src/MyContract.sol:MyToken --constructor-args asuna ASU 18 100000 -verify: 验证合约，即在浏览器中开源合约的源码 \u0026ndash;private-key: 钱包私钥 \u0026ndash;constructor-args: 部署合约构造函数参数 验证合约:\nforge verify-contract forge verify-contract \\ --chain-id 11155111 \\ --num-of-optimizations 1000000 \\ --watch \\ --constructor-args $(cast abi-encode \u0026#34;constructor(string,string,uint256,uint256)\u0026#34; \u0026#34;ForgeUSD\u0026#34; \u0026#34;FUSD\u0026#34; 18 1000000000000000000000) \\ --etherscan-api-key \u0026lt;your_etherscan_api_key\u0026gt; \\ --compiler-version v0.8.10+commit.fc410830 \\ \u0026lt;the_contract_address\u0026gt; \\ src/MyToken.sol:MyToken 脚本部署合约 // SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.25; import {Script} from \u0026#34;forge-std/Script.sol\u0026#34;; import \u0026#34;../src/MyToken.sol\u0026#34;; contract MyTokenScript is Script { function run() external { uint256 deployer = vm.envUint(\u0026#34;PRIVATE_KEY\u0026#34;); vm.startBroadcast(deployer); MyToken myToken = new MyToken(\u0026#34;MyToken\u0026#34;, \u0026#34;MT\u0026#34;, 18, 1000000000000000000); vm.stopBroadcast(); } } forge script script/MyTokenScript.s.sol:MyTokenScript --broadcast --rpc-url \u0026lt;RPC_URL\u0026gt; --private-key \u0026lt;YOUR_PRIVATE_KEY\u0026gt; vm.startBroadcast(): 标记从这一点开始的所有交易都应该被广播。这意味着在vm.startBroadcast()和vm.stopBroadcast()之间的所有操作都会被记录并准备广播。 --broadcst: 广播交易，执行实际部署操作广播到区块链网络。不加则只是模拟部署过程。 这个部署脚本本身就是一个智能合约。脚本是通过调用名为run的函数来执行的\nCast cast是foundry用于执行以太坊RPC调用的命令行工具。\ncast \u0026lt;subcommand\u0026gt; 获取链上信息 直接使用 cast call 0x6b175474e89094c44da98b954eedeac495271d0f \u0026#34;totalSupply()(uint256)\u0026#34; --rpc-url \u0026lt;your rpc url\u0026gt; 8603853182003814300330472690 2. 设置\u0026ndash;rpc-url\nexport ETH_RPC_URL=\u0026#34;https://eth-mainnet.alchemyapi.io/v2/Lc7oIGYeL_......\u0026#34; 设置了RPC URL后，就不需要每次运行命令时单独设置\n#获取链id cast chain-id #获取client cast client #链的名称 cast chain #gas价格 cast gas-price 获取区块信息 #最新区块号 cast block-number # 获取指定区块的基础费用 cast basefee 6139522 #区块的时间戳 cast age 获取账户信息 #获取指定账户的金额,单位是 wei cast balance \u0026lt;address\u0026gt; #指定ENS名称查询余额 cast balance vitalik.eth 发送交易 调用合约函数 cast send --private-key \u0026lt;private_key_addr\u0026gt; \u0026lt;contract_addr\u0026gt; \u0026#34;exampleFunc(uint256)\u0026#34; \u0026lt;argument_value_of_the_function\u0026gt; # 案例 cast send --private-key 0x7a53f0a5f517ecb17943179a7eb351227607ee7bb01c2ca9d1785ea4ade5f147 0xf404916d6A17ca37584a9f673a40c1F839825fC9 \u0026#34;balanceOf(address)\u0026#34; 0x3C2c4Cd3d0F7902FD72700D98fad2750746e03d6 如果调用合约中不存在的函数，将自动触发Fallback函数.这可以用于测试合约的异常处理或特定的功能。\ncast send --private-key 0x123... 0xabc... \u0026#34;dummy()\u0026#34; 通过向合约发送以太币（Ether），可以触发合约的 Receive 函数。这对于接受捐款或处理支付非常有用。\ncast send --private-key \u0026lt;private_key_addr\u0026gt; \u0026lt;contract_addr\u0026gt; --value 10gwei 获取合约代码 cast etherscan-source \u0026lt;contract-address\u0026gt; # 案例 cast etherscan-source 0xf404916d6A17ca37584a9f673a40c1F839825fC9 获取链上Storage槽的private状态变量 cast storage 0x5FbDB2315678afecb367f032d93F642f64180aa3 1 --rpc-url http://localhost:8545 将bytes32转为string cast parse-bytes32-string 0x6d696b617361000000000000000000000000000000000000000000000000000c 获取合约所有storage变量 forge inspect \u0026lt;contract_name\u0026gt; \u0026lt;option\u0026gt; forge inspect PasswordStore storage 解析函数的返回值 # 1 cast abi-decode \u0026#34;name()(string)\u0026#34; \\ 0x000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000084f7572546f6b656e000000000000000000000000000000000000000000000000 # 2 cast call 0x0165878A594ca255338adfa4d48449f69242Eb8F \u0026#34;balanceOf(address)\u0026#34; 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266 | cast to-dec Anvil Anvil是Foundry套件的一部分，专为提供一个便于本地测试和开发的以太坊节点而设计。Anvil与Forge、Cast、Chisel一起为智能合约开发者提供了一个完整的工具集，以支持从开发到测试的整个生命周期。\nAnvil的功能和重要性 Anvil允许开发者在本地环境中运行一个轻量级的以太坊节点，这使得从前端测试智能合约或通过RPC接口与合约进行交互变得简单快捷。\n安装 运行 foundryup 来更新到最新版本，确保所有工具都是最新的\n运行 # 运行 anvil #查看帮助 anvil -h #生成10个开发账户 anvil -a 10 #设置硬分叉版本 anvil --hardfork \u0026lt;HARDFORK\u0026gt; #设置监听端口 anvil -p \u0026lt;PORT\u0026gt; #创建从网络复制分叉在本地创建一个节点，从第500000个区块开始 anvil --fork-url https://sepolia.infura.io/v3/\u0026lt;YOUR_KEY\u0026gt; --fork-block-number 500000 Chisel Chisel 是一个 Solidity REPL（\u0026ldquo;读取-评估-打印 循环 \u0026ldquo;的缩写），它允许开发人员编写和测试 Solidity 代码片段。\n启动 Chisel 非常简单，只需在命令行中输入 chisel 即可。启动后，你可以直接在命令行中编写和测试 Solidity 代码。\nForge标准库 Forge Std的核心是其测试合约Test.sol\n使用Forge Std，只需要导入Test.sol,并测试合约中继承Test:\nimport \u0026#34;forge-std/Test.sol\u0026#34;; contract ContractTest is Test { // 测试代码 } 核心功能\n访问Hevm:通过vm实例可以直接使用cheatcodes来模拟各种区块链状态和行为。 断言与日志记录 标准库各种实用工具 包含的库\nStd Logs Std Assertions 对DSTest库中的断言函数进行了扩展 Std Cheats Std Error Std Storage 测试 作弊码(Cheatcode) 作弊码允许开发者在测试中执行一系列非标准操作，比如更改区块好、修改调用者身份等。\n身份切换: vm.prank 预期还原: vm.expectRevert 事件验证：vm.expectEmit 编写测试 导入forge-std/Test.sol继承Test\npragma solidity 0.8.10; import \u0026#34;forge-std/Test.sol\u0026#34;; contract MyTest is Test { // 测试代码 } setUp 是一个可选函数，会在每个测试用例运行前被调用，用于初始化测试环境\ntest为前缀被识别为测试用例\ntestFail为前缀的函数，测试预期失败，没有触发revert，则测试失败\n执行测试 全局测试\nforge test 指定测试\n# 此命令将仅运行名为ComplicatedContractTest的测试合约中包含test_Deposit的测试函数。 forge test --match-contract ComplicatedContractTest --match-test test_Depsosit Glob模式\nforge test --match-path test/ContractB.t.sol 在分叉上测试\nforge test --fork-url \u0026lt;RPC_URL\u0026gt; 观察模式\nforge test --watch 对文件更改时，forge可以重新运行测试 forge test --watch --run-all 更改时，重新运行所有测试 执行后颜色标识 黄色：有触发 revert 的调用 红色：触发revert的调用 蓝色：对Cheatcodes的调用 青色：已发出的日志 黄色：合约部署 分叉测试 # 1 forge test --fork-url \u0026lt;your_rpc_url\u0026gt; # 2 forge test --fork-url \u0026lt;your_rpc_url\u0026gt; --fork-block-number 1 # 3 forge test --fork-url \u0026lt;your_rpc_url\u0026gt; --etherscan-api-key \u0026lt;your_etherscan_api_key\u0026gt; 三种分叉测试方式 vm.createFork()：用于测试过程中动态创建分叉，适用于需要在测试中频繁切换分叉的场景。 anvil --fork-url：用于启动本地节点并创建分叉，适用于本地环境的持续开发和测试。 forge test --fork-url：用于在测试环境中创建分叉，并在该分叉上运行所有测试，适用于需要在分叉环境中进行全面测试的场景。 分叉作弊码 分叉作弊码允许我们在solidity测试代码中直接创建、选择和管理多个分叉。每个奉茶通过一个唯一的uint256标识在识别。\n*** 重要的是要记住，所有测试函数都是隔离的，这意味着每个测试函数都在setUp后的状态副本中执行，并在其自己的独立 EVM 中执行。因此，在setUp期间创建的分叉在测试中可用。**\n分叉的独立和持久性 每个分叉都是一个独立的EVM，使用完全独立的存储。msg.sender和测试合约本省的状态在分叉间时持久的。\n持久性账户允许我们在一个分叉环境中创建和修改状态，并在另一个分叉环境中保持这些状态不变。\ncontract SimpleStorageContract { uint256 public value; function set(uint256 _value) public { value = _value; } } // 创建并测试持久性合约 function testCreatePersistentContract() public { // 首先，选择一个分叉环境 vm.selectFork(mainnetFork); // 在该分叉环境中部署并初始化合约 SimpleStorageContract simple = new SimpleStorageContract(); simple.set(100); // 确认合约的状态设置正确 assertEq(simple.value(), 100); // 接下来，将合约标记为持久性 vm.makePersistent(address(simple)); // 验证合约已被正确标记为持久性 assert(vm.isPersistent(address(simple))); // 然后，切换到另一个分叉环境 vm.selectFork(optimismFork); // 验证即使在新的分叉环境中，合约仍被标记为持久性 assert(vm.isPersistent(address(simple))); // 最后，确认持久性合约的状态在新的分叉环境中保持不变 assertEq(simple.value(), 100); } 模糊测试 单元测试 import \u0026#34;forge-std/Test.sol\u0026#34;; contract SafeTest is Test { Safe safe; function setUp() public { safe = new Safe(); } function test_Withdraw() public { payable(address(safe)).transfer(1 ether); uint256 preBalance = address(this).balance; safe.withdraw(); uint256 postBalance = address(this).balance; assertEq(preBalance + 1 ether, postBalance); } } 属性测试 在Foundry中，任何待用参数的测试函数都会被视为属性测试\nfunction testFuzz_Withdraw(uint256 amount) public { payable(address(safe)).transfer(amount); uint256 preBalance = address(this).balance; safe.withdraw(); uint256 postBalance = address(this).balance; assertEq(preBalance + amount, postBalance); } 排除特定情况 使用vm.assume作弊码。可以排除某些不希望进行测试的特定情况。\nfunction testFuzz_Withdraw(uint96 amount) public { vm.assume(amount \u0026gt; 0.1 ether); // 测试逻辑... } Fuzz Testing优势 自动化测试 广泛的覆盖率 灵活性高 单元测试,属性测试完整案例 // SPDX-License-Identifier: MIT pragma solidity ^0.8.22; contract Safe{ receive() external payable{} constructor() payable{} function withdraw() public{ payable(msg.sender).transfer(address(this).balance); } } // SPDX-License-Identifier: MIT pragma solidity ^0.8.22; import \u0026#34;forge-std/Test.sol\u0026#34;; import \u0026#34;src/Safe.sol\u0026#34;; contract SafeTest is Test{ Safe safe; function setUp() public{ safe = new Safe(); } receive() external payable{} //单元测试 function test_Withdraw() public { payable(address(safe)).transfer(1 ether);//给合约转 1 ether uint256 preBalance = address(this).balance; safe.withdraw();//取出合约中的所有金额给msg.sender uint256 postBalance = address(this).balance;//取出后合约的余额 assertEq(preBalance + 1 ether, postBalance); } //属性测试 //在进行 Fuzz Testing 时，可能会遇到高值输入导致测试失败的情况。 //例如，当amount超过合约拥有的余额时，测试将失败。 //为了解决这个问题，可以限制amount的类型为uint96，以确保输入值在合理的范围内。 function testFuzz_Withdraw(uint96 amount) public{ //amount必须大于0.1 ether vm.assume(amount \u0026gt; 0.1 ether); payable(address(safe)).transfer(amount); uint256 preBalance = address(this).balance; safe.withdraw(); uint256 postBalance = address(this).balance; assertEq(preBalance + amount, postBalance); } } 不变性测试 允许对预定义合约中预定义函数调用的随机序列进行测试，并在每次函数调用后断言一组不变表达式。\n不变性的测试维度：\n运行(runs) 深度(depth) 不变量 不变量是在模糊测试过程中始终保持真实的条件表达式。一个好的不变性测试套件应尽可能多地包含不变量。\n不变量例子：\n对于Uniswap,\u0026ldquo;xy=k公式始终成立\u0026rdquo;。 对于ERC-20代币，\u0026ldquo;所有用户余额之和等于总供应量\u0026rdquo;。 差异化测试 差异测试是一种通过比较同一功能的多个实现的输出来找出错误的测试方法。\n差异测试的核心是交叉验证。例如，如果我们有一个功能规范 F(X) 和该规范的两个实现 f1(X) 和 f2(X)，我们期望对于所有合理的输入 x，f1(x) 应该等于 f2(x)。如果 f1(x) 不等于 f2(x)，那么我们知道至少有一个实现是错误的。\n差异测试特别适用于以下情况：\n将升级后的实现与其早期版本进行比较。 对照已知的参考实现测试代码。 确认与第三方工具和依赖项的兼容性。 差异化测试案例 // Solidity 版本的默克尔树实现 function generateMerkleRoot(bytes32[] memory leaves) public pure returns (bytes32) { // 示例代码：具体实现细节省略 return keccak256(abi.encodePacked(leaves)); } function testMerkleRootMatchesJSImplementation(bytes32[] memory leaves) public { string[] memory args = new string[](3); args[0] = \u0026#34;node\u0026#34;; args[1] = \u0026#34;./calculateMerkleRoot.js\u0026#34;; args[2] = leaves.toHexString(); // 假设已实现转换为 hex 字符串的功能 //vm.ffi 调用外部实现 bytes memory jsResult = vm.ffi(args); bytes32 jsMerkleRoot = abi.decode(jsResult, (bytes32)); bytes32 solMerkleRoot = generateMerkleRoot(leaves); assertEq(solMerkleRoot, jsMerkleRoot, \u0026#34;Merkle roots do not match\u0026#34;); } 模拟主网分叉 模拟主网分叉是指将一个活跃的区块链网络的状态复制到本地，并在本地环境中使用，通常 用于按照实际网络环境的状态来测试你的智能合约。\n启动分叉 # 配置 RPC-URL anvil --fork-url \u0026lt;YOUR_ENDPOINT_URL\u0026gt; --form-block-number 1900000 --fork-url 标签用于从远端获取区块链状态 --fork-block-number 用于从特定区块号开始分叉区块链状态 常见错误 OutOfFunds：在区块链和智能合约的上下文中，\u0026ldquo;OutOfFunds\u0026rdquo;（资金不足）是一个常见的错误或异常情况 PrecompileOOG：指在执行预编译合约（Precompiled Contracts）时遇到的\u0026quot;Out of Gas\u0026rdquo;（OOG）错误，交易提供的Gas不足以覆盖执行所需的全部Gas时 transfer 转账有gas限制,而使用call方法没有 division or modulo by zero：如果你尝试进行除法或取模运算，并且除数为0，那么会触发一个运行时错误，导致交易被回滚 ","date":"2024-06-20T00:00:00Z","image":"https://wushengyouya.github.io/p/foundry/image-1.png","permalink":"https://wushengyouya.github.io/p/foundry/","title":"Foundry"},{"content":"安装protobuf组件 go-zero框架使用goctl命令安装 # 1.安装goctl go install github.com/zeromicro/go-zero/tools/goctl@latest ```sh ##执行goctl检查是否安装陈工 goctl -v ``` # 2.使用goctl命令 一键安装protoc，protoc-gen-go，protoc-gen-go-grpc goctl env check --install --verbose --force ## --force 静默安装 ## --verbose 输出执行日志 # 检查环境安装是否成功 goctl env check --verbose goctl安装protoc不成功,从 protoc-github仓库地址下载对应的系统版本， 放入gopath目录中 #执行命令检查是否安装陈工 protoc ","date":"2024-06-19T00:00:00Z","image":"https://wushengyouya.github.io/p/go-zero/go-zero%E8%B0%83%E7%94%A8%E5%85%B3%E7%B3%BB.png","permalink":"https://wushengyouya.github.io/p/go-zero/","title":"go-zero"},{"content":"npm install 执行出现的问题 Error: error:0308010C:digital envelope routines::unsupported npm版本问题，解决方案一般是这两个\n执行命令 # linux: set NODE_OPTIONS=--openssl-legacy-provider # windows export NODE_OPTIONS=--openssl-legacy-provider 修改package.json文件 //加入这两句 \u0026#34;scripts\u0026#34;:{ \u0026#34;serve\u0026#34;: \u0026#34;SET NODE_OPTIONS=--openssl-legacy-provider \u0026amp;\u0026amp; vue-cli-service serve\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;SET NODE_OPTIONS=--openssl-legacy-provider \u0026amp;\u0026amp; vue-cli-service build\u0026#34; } 安装命令 npm install --registry https://registry.npmmirror.com ","date":"2024-06-19T00:00:00Z","permalink":"https://wushengyouya.github.io/p/npm%E7%89%88%E6%9C%ACbug/","title":"npm版本bug"},{"content":"\n面试题目 面试过程中面试官提问的一些问题。经过几个面试过程，总结出有些公司问八股文，有些公司喜欢挖掘项目。问项目中某一项技术实现原理。\n2024-3-15 go中实现共享内存的方式 怎么关闭一个go协程 Mysql中聚簇索引与非聚簇索引的区别，使用什么数据结构来实现的，查询数据的流程是什么 GMP的调用流程 Map的内部实现机制,如果不初始化可以写入值吗，可以取值吗 chan有哪几种，区别是什么，如果一个chan没初始化是什么状态，发生读写操作会发生什么 常见的设计模式有哪几种，项目中是怎么实现责任链设计模式的 在什么场景需要创建索引，什么字段适合作为索引使用 其他 grpc与http协议的区别 linux中如何查询公网ip curl ifconfig.me curl cip.cc 项目中你用了协程池，你是怎么实现的 数据库的分表是什么 如何实现一个高并发的邮件系统“同时又很多邮件发送过来” 数组与链表的区别 你在写项目中遇到印象最深的一个bug是什么，你是怎么处理的 go中怎么处理高并发的问题 如果一个sql查询很慢，做了任何优化手段后仍然很慢，该怎么处理 这个问题感觉问的是有问题的，sql查询慢一般是具体问题具体分析为什么会查询慢 10.\n","date":"2024-03-15T00:00:00Z","image":"https://wushengyouya.github.io/image.png","permalink":"https://wushengyouya.github.io/p/%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","title":"面试汇总"},{"content":"consul Consul是一个服务网格解决方案，提供了一个功能齐全的控制平面，具有服务发现、配置和分段功能。这些功能中的每一项都可以根据需要单独使用，也可以一起使用来构建一个完整的服务网格。\n服务发现 健康检查 KV存储 安全服务通信 多数据中心 常用命令 consul agent --dev # 开启开发者模式 服务端consul 引入consul包\nimport \u0026#34;github.com/hashicorp/consul/api\u0026#34; 初始化服务发现consul defaultConfig := api.DefaultConfig() client, err := api.NewClient(defaultConfig) if err != nil { log.Println(err) } 注册服务 client.Agent().ServiceRegister(\u0026amp;api.AgentServiceRegistration{ //需要注册的服务信息 ID: \u0026#34;1\u0026#34;, Name: \u0026#34;HelloService\u0026#34;, Tags: []string{\u0026#34;test1\u0026#34;, \u0026#34;tag\u0026#34;}, Address: \u0026#34;127.0.0.1\u0026#34;, Port: 8810, //检查服务 Check: \u0026amp;api.AgentServiceCheck{ CheckID: \u0026#34;consul check id\u0026#34;, TCP: \u0026#34;127.0.0.1:8810\u0026#34;, Timeout: \u0026#34;10s\u0026#34;,//超时 Interval: \u0026#34;10s\u0026#34;, }, }) 绑定grpc //1.创建grpc服务 grpcServer := grpc.NewServer() //2.注册服务 pb.RegisterHelloServer(grpcServer, new(Student)) //3.监听 listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8810\u0026#34;) if err != nil { log.Println(err) } defer listen.Close() fmt.Println(\u0026#34;开始监听....\u0026#34;) //4.绑定监听 grpcServer.Serve(listen) 客户端consul 初始化consul //初始化consul defaultConfig := api.DefaultConfig() c, err := api.NewClient(defaultConfig) if err != nil { log.Println(err) } 获取健康的服务 //获取健康的服务 sevices, _, err := c.Health().Service(\u0026#34;HelloService\u0026#34;, \u0026#34;test1\u0026#34;, true, nil) if err != nil { log.Println(err) } 获取服务发现已注册的ip、port //获取服务发现上的ip port addr := fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, sevices[0].Service.Address, sevices[0].Service.Port) fmt.Println(addr) 注册grpc //1.连接服务器 clientConn, err := grpc.Dial(addr, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Println(err) } //2.初始化客户端 hc := pb.NewHelloClient(clientConn) p := \u0026amp;pb.Person{ Name: \u0026#34;李白\u0026#34;, Age: 11, } //3.调用 p2, err2 := hc.SayHello(context.Background(), p) if err2 != nil { log.Println(err2) } fmt.Println(p2) etcd etcd 是一种开源的分布式键值存储库，用于保存和管理分布式系统保持运行所需的关键信息。\n#docker安装 docker run --name etcd -d -p 2379:2379 -e ALLOW_NONE_AUTHENTICATION=yes bitnami/etcd 常用命令 #设置或者更新值 etcdctl put name 张三 #获取值 etcdctl get name #只要value etcdctl get name --print-value-only #获取name前缀的键值对 etcdctl get --prefix name #删除键值对 etcdctl del name #监听键的变化 etcdctl watch name etcd与redis区别 redis是一种内存中的数据存储库，可用作数据库、缓存、消息代理。redis支持的数据类型要比etcd多，其读写性能也快得多 etcd具有超强的容错能力以及更强的故障转移和持续数据可用性能力 etcd将所有数据存储在硬盘上 redis更实用用作分布式缓存系统，而不是存储分布式配置信息 ","date":"2024-01-29T00:00:00Z","image":"https://wushengyouya.github.io/p/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image.png","permalink":"https://wushengyouya.github.io/p/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/","title":"服务发现"},{"content":"人生百年，蜉蝣一日。人生如棋，落子无悔。 问道之心，终归难改。\n","date":"2024-01-27T00:00:00Z","permalink":"https://wushengyouya.github.io/p/%E5%87%A1%E4%BA%BA%E4%BF%AE%E4%BB%99%E4%BC%A0/","title":"凡人修仙传"},{"content":"SELECT的执行流程 连接器：建立连接，管理连接，校验身份 查询缓存：查询语句如果命中缓存则直接返回，否则继续往下执行。Mysql 8.0已删除。 解析SQL：通过解析器对SQL查询进行词法分析，语法分析，然后构建语法树 执行SQL：执行SQL共有三个阶段 预处理阶段：检查表或字段是否存在，将selct *中的*符号扩展为表上所有的列 优化阶段：基于查询成本考虑，选择查询成本最小的执行计划 执行阶段：根据执行计划执行SQL查询语句，从存储引擎读取记录，返回给客户端 、 数据是怎么存储的 MySql硬盘文件\n*.opt：存储当前数据库的默认字符集和字符校检规则\n*.frm：存储表结构\n*.ibd：存储表数据\n表空间文件的结构是怎么样的？ 表空间由段（segment）、区（extent）、页（page）、行（row）组成\n行: 数据库表中的记录都是按行进行存放的，每行记录根据不同的行格式，有不同的存储结构。 页：记录是按行来存储的，但是数据库并不以行为单位，否则一次读取就是一次I/O操作。InnoDB的数据是按页为单位来读取的 ，默认每个页的大小为16kb。 区：在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了 段：表空间是由各个段（segment）组成的，段是由多个区（extent）组成的 InnoDB 行格式有哪些？ InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。\nRedundant 是很古老的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。 Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。 Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多。从 MySQL5.7 版本之后，默认使用 Dynamic 行格式 Compact格式：\n变长字段长度列表：varchar(n) 和 char(n) 的区别是什么，相信大家都非常清楚，char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。「变长字段长度列表」的信息是按照逆序存放的\nNULL值列表：表中的某些列可能会存储 NULL 值，Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中默认占1个字节 如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。\n记录头信息：delete_mask标识是否被删除，next_record下一条记录的位置\n二进制位的值为1时，代表该列的值为NULL。\n二进制位的值为0时，代表该列的值不为NULL。 varchar(n) 中 n 最大取值为多少？ MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。 一行数据的最大字节数 65535，其实是包含「变长字段长度列表」和 「NULL 值列表」所占用的字节数的。所以， 我们在算 varchar(n) 中 n 最大值时，需要减去 storage overhead 占用的字节数。 如果有多个字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 \u0026lt;= 65535。 行溢出后，MySQL 是怎么处理的？ 发生行溢出，多的数据就会存到另外的「溢出页」中。 索引 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。\n按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。\n按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。\n按「字段个数」分类：单列索引、联合索引。 创建的主键索引和二级索引默认使用的是 B+Tree 索引。\n主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：\n主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 B+树 B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是按主键顺序存放的。 每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一 个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。\n优点:\nB+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I/O， 所以B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。\n回表 如果我用 product_no 二级索引查询商品，如下查询语句： select * from product where product_no = '0002'; 会先检二级索引中的 B+Tree 的索引值（商品编码，product_no），找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据。\n覆盖索引 在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。\nMysql什么使用B+树而不适用B树 B+树只在叶子节点存储数据，而B树的非叶子节点也要存储数据，所以B+树的单个节点的数据量更小，在相同的磁盘I/O次数下，就更查询更多的节点。\n为什么不适用Hash索引 hash索引适合单个查询，不适用于进行范围查询\n什么时候适用索引？ 字段有唯一限制的，比如商品编码 经常用于where条件的 经常用于GROUP BY和ORDER BY的字段。这样在查询的时候就不需要再去做一次排序，因为我们知道建立索引之后再B+树的记录是排序号的 有什么优化索引的方法？ 前缀索引优化； 覆盖索引优化； 主键索引最好是自增的 InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。\n如果我们使用自增主键，插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。\n如果我们使用非自增主键，每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入,通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。\n防止索引失效； 索引最好设置为 NOT NULL 事务 事务有哪些特性 原子性 一致性 隔离性 持久性 并行事务会引发什么问题？ 脏读 如果一个事务读到了另一个 未提交事务修改过的数据 ，就意味着发生了脏读 2. 不可重复读 在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了 不可重复读 现象。\n3. 幻读 在一个事务内多次查询某个符合查询条件的 记录数量，如果出现前后两次查询到的记录数量不一样，就意味着发生了幻读现象\n三者严重性：\n事务的隔离级别有哪些？ 读未提交：一个事务还没提交时，他做的变更就能被其他事务看到 读已提交：一个事务提交后，他做的变更就能被其他事务看到 可重复读：一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，Mysql InnoDB引擎的默认隔离级别 串行化：会对记录加上锁，在多个事务对这条记录进行读写操作是，如果发生了冲突的时候，后访问的事务必须等待前一个事务实行完成。 四种隔离级别具体是如何实现的呢 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。 启动事务:\n执行了 begin/start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了第一条 select 语句，才是事务真正启动的时机； 执行了 start transaction with consistent snapshot 命令，就会马上启动事务。 ","date":"2023-03-02T00:00:00Z","image":"https://wushengyouya.github.io/p/mysql/head.png","permalink":"https://wushengyouya.github.io/p/mysql/","title":"mysql"},{"content":"网络分层 常见的网络模型分为OSI七层模型与TCP/IP四层模型，OSI因为比较复杂实现起来麻烦，使用的不多。通常用TCP/IP 的四层网络模型。\nOSI模型 应用层 表示层 会话层 传输层 网络层 数据链路层 物理层 TCP/IP模型 应用层：HTTP FTP GRPC 传输层：TCP UDP 网络层：IP 网络接口层 数据包封包解包流程 什么是HTTP 超文本传输协议,是网络中最常见的通讯协议。基于传输层TCP协议构建的应用层协议，数据采用明文传输，安全性差。 Get 与 Post 「幂等」，意思是多次执行相同的操作，结果都是「相同」的。\n「安全」是指请求方法不会「破坏」服务器上的资源。\nGET:从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等。浏览器对URL的请求长度有限制，HTTP没有。所有来说GET请求是用长度限制的。GET请求是安全幂等的。\nPOST:新增或提交数据。因为会修改服务器上的资源所以是不安全的，因为会多次提交数据所以是不幂等的。\nHTTP 常见的状态码 HTTP通过什么解决粘包问题的 HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题。\nHTTP和HTTPS有什么区别 HTTP是超文本传输协议，信息是明文传输的，存在安全问题。HTTPS则解决HTTP不安全的问题，在TCP和HTTP网络层之间加入SSL/TLS安全协议，是得报文能够加密传输。 HTTP连接建立相对简单，TCP三次握手后便可进行HTTP的报文传输。而HTTPS在TCP三次握手后还需进行SSL/TLS的握手过程，才可进行加密报文传输。 两者端口不一样HTTP是80端口，HTTP是443端口。 HTTPS协议需要向CA(证书权威结构)申请数字证书，来保证服务器的身份是可靠的。 HTTPS解决了什么问题 窃听风险 篡改风险 冒充风险 HTTP/2改进在哪 队头堵塞： HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。 兼容HTTP/1.1 使用HPACK 算法压缩请求头 为高频出现在头部的字符串和字段建立了一张静态表 将 HTTP/1 的文本格式改成二进制格式传输数据 多个 Stream 复用一条 TCP 连接，达到并发的效果，解决了 HTTP/1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。 缺陷 队头阻塞 TCP 与 TLS 的握手时延迟 网络迁移需要重新连接 HTTP/3 将TCP协议改成了UDP,并在UDP上开发了QUIC协议来保障数据传输的可靠性\n无队头堵塞 建立连接速度更快 输入网址到展示发什么了 解析URL地址生成HTTP请求报文 进行DNS域名解析获取IP。先查看缓存如果有就直接返回 没有再去hosts文件查看，如果再没没有则发送DNS请求询问本地的DNS服务器 DNS获取到Ip后，就可以把HTTP协议的传输工作交给操作系统的协议栈 （HTTP是基于TCP协议传输数据前，要先进行TCP三次握手） TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块 将数据封装成网络包发送给通信 查找mac地址，先查路由表，如果路由表没有就通过ARP协议广播查找mac地址 将数据包通过网卡发送到交换机，交换机再发送到服务器 什么是TCP TCP是面向连接的、可靠的、基于字节流的传输层通信协议\nTCP数据格式:\nTCP的三次握手和四次挥手 TCP三次握手中，只有第三次握手是可以携带数据的，前两次握手是不可以携带数据的 第一次握手丢失了，会发生什么 客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。每次超时的时间是上一次的 2 倍。\n第二次握手丢失了 客户端和服务端都会重传\n服务端那一方迟迟收不到这个ACK确认报文，就会触发超时重传机制 (ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文) 为什么挥手需要四次？ 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 第一次挥手丢失 客户端迟迟收不到被动方的 ACK 的话,触发客户端重传FIN\n第二挥手丢失 服务端的第二次挥手丢失了，客户端就会触发超时重传机制,重传 FIN 报文\n第三次挥手丢失 服务端就会重发 FIN 报文\n第四次挥手丢失 客户收到FIN报文消息后，回复ACK确认消息。回复的ACK未到达服务器，服务端就会重发 FIN 报文。\n什么是UDP UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。DNS采用UDP协议\nUDP的数据格式：\nTCP和UDP的区别 连接 TCP是面向连接的传输层协议，传输数据前要先建立连接 UDP是不需要连接，即刻传输数据 服务对象 TCP是一对一的两点服务，即一条连接只有两个端点 UDP支持一对一、一对多、多对多的交互通信 可靠性 -TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达 -UDP是尽最大努力交付，不保证可靠交付数据。但我们可以基于UDP传输协议实现一个可靠的传输协议，比如QUIC协议。 拥塞控制、流量控制 TCP有拥塞控制和流量控制，保证数据传输的安全性 UDP则没有，即使网络非常堵了，也不会影响UDP的转发速率 5.首部开销 TCP首部长度较长，会有一定的开销 UDP首部只有8个字节，并且是固定不变的开销小 为什么需要 TIME_WAIT 状态？ 保证被关闭的一方能被正常关闭\n为什么 TIME_WAIT 等待的时间是 2MSL TODO\n服务器出现大量 CLOSE_WAIT 状态的原因有哪些？ 当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。\n服务器出现大量 TIME_WAIT 状态的原因有哪些？ 说明服务器主动断开了很多 TCP 连接。\n第一个场景：HTTP 没有使用长连接\n第二个场景：HTTP 长连接超时\n第三个场景：HTTP 长连接的请求数量达到上限\nSOCKET 每一个socket执行listen时，内核都会自动创建一个半连接队列和全连接队列。 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。 accept方法只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎毫无关系。 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了哈希表，而全连接队列本质是链表。 全连接队列满了，再来第三次握手也会丢弃，此时如果tcp_abort_on_overflow=1，还会直接发RST给客户端。 半连接队列满了，可能是因为受到了SYN Flood攻击，可以设置tcp_syncookies，绕开半连接队列。 客户端没有半连接队列和全连接队列，但有一个全局hash，可以通过它实现自连接或TCP同时打开。 TCP 半连接和全连接队列 在TCP三次握手的时候。Linux内核会维护两个队列，分别是：\n半连接队列，也称SYN队列 全连接队列,也成ACCEPT队列 半连接队列与全连接队列的工作流程: 避免 SYN 攻击方式，可以有以下四种方法 SYN攻击是未知客户端一直向服务器发送SYN报文，将半连接队列撑满。\n增大TCP的半连接队列 减少SYN+ACK的重传次数 调大 netdev_max_backlog 开启 tcp_syncookies IP IP 则负责在「没有直连」的两个网络之间进行通信传输 分类 IP地址分为A B C D E 五大类。A、B、C 类主要分为两个部分，分别是网络号和主机号 无分类地址 CIDR 因为 IP 分类存在许多缺点，所以后面提出了无分类地址的方案，即 CIDR。\n这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是网络号，后面是主机号。\na.b.c.d/x，其中 /x 表示前 x 位属于网络号， x 的范围是 0 ~ 32 10.100.122.2/24，这种地址表示形式就是 CIDR，/24 表示前 24 位是网络号，剩余的 8 位是主机号。\n子网掩码:\n另一种划分网络号与主机号形式，那就是子网掩码，掩码的意思就是掩盖掉主机号，剩余的就是网络号。\n将子网掩码和 IP 地址按位计算 AND，就可得到网络号。\nIP 地址与路由控制 PING工作原理 ICMP: 确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 1.客户端在网络层封装IP报文、ICMP标识为8的回送请求报文发送给指定服务器\n2.路由器接收到报文消息后先查路由表如果没有该IP指定的MAC地址\n使用ARP协议广播获取MAC地址\n3.如果能连接上就反回ICMP 为0的回复应答报文\n4.不能连接上，路由器回复ICMP 异常报文\n","date":"2023-03-02T00:00:00Z","image":"https://wushengyouya.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/image.png","permalink":"https://wushengyouya.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","title":"计算机网络"},{"content":"特性 go的语法简洁明了，易于学习和阅读便于学习。 是一种编译型语言，go代码会被编译成机器码，执行效率高启动速度快 go天然支持高并发提供了goroutine来处理并发操作，channel用于goroutine之间的通信。go并发模型 基于“不要通过共享内存来通信，而是通过通信来共享内存” 自带垃圾回收机制，降低了内存泄漏的风险 go鼓励使用组合而不是继承来组织和复用代码。它的结构体（structs）可以嵌入其他类型。 关键字(25个) 关键字 描述 break 用于终止当前循环 case switch 语句中的一个分支 chan 表示一个通道类型 const 定义常量 continue 跳过当前循环的剩余代码，开始下一次循环 default switch 或 select 语句中的默认分支 defer 延迟执行一个函数直到上层函数返回 else if 语句中的否则分支 fallthrough 在 switch 语句中强制执行下一个 case for 循环语句 func 定义一个函数 go 启动一个新的 goroutine goto 转到一个标签 if 条件语句 import 引入包 interface 定义一个接口 map 表示一个映射类型 package 定义一个包 range 迭代数组、切片、字符串、映射或通道 return 从函数中返回 select 选择不同类型的通讯 struct 定义一个结构体 switch 条件分支语句 type 类型定义或类型别名 var 定义一个变量 import //导入单个包 import \u0026#34;fmt\u0026#34; //导入多个 import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) 包管理 go默认采用go mod进行包管理\ngo mod init temp.github.com #初始化 go mod tidy #添加缺少的模块，移除不再需要的模块 go mod download #下载模块 go mod list #列出模块 go mod graph #打印模块依赖图 main函数 package main import \u0026#34;fmt\u0026#34; func main(){ //执行内容 } 变量与常量 //1.定义再赋值 var name string name = \u0026#34;mikasa\u0026#34; //2.定义直接赋值 var age = 10 var gender = \u0026#34;man\u0026#34; fmt.Printf(\u0026#34;name : %s,age : %d,gender:%s\\n\u0026#34;, name, age, gender) //3.自动推导赋值 adress := \u0026#34;背景\u0026#34; fmt.Println(\u0026#34;adress:\u0026#34;, adress) //4.平行赋值 i, j := 10, 20 fmt.Println(\u0026#34;i:\u0026#34;, i, \u0026#34;j:\u0026#34;, j) i, j = j, i//交换两个变量的位置 fmt.Println(\u0026#34;i:\u0026#34;, i, \u0026#34;j:\u0026#34;, j) //通过字符串创建了一个切片 str11 := \u0026#34;abcdefljin\u0026#34; str22 := str11[2:4] fmt.Println(str22) //定义常量 const conNum = 5 const con string = \u0026#34;10\u0026#34; const ( a = 1 b = 2 ) 自增与自减 //go里面没有 --i ++i //只有i++ i-- 且必须只能独占一行 i := 2 i++ i-- 数组及遍历 for-range底层实现\nfor-range典型面试问题\n1.\nfunc main() { arr := []int{1, 2, 3} for _, v := range arr { arr = append(arr, v) } fmt.Println(arr) } $ go run main.go 1 2 3 1 2 3 2.\nfunc main() { arr := []int{1, 2, 3} newArr := []*int{} for _, v := range arr { newArr = append(newArr, \u0026amp;v) } for _, v := range newArr { fmt.Println(*v) } } $ go run main.go 3 3 3 //定义一个长度为10的数组 nums := [10]int{1, 2, 3, 4} //数组的遍历方法1 for i := 0; i \u0026lt; len(nums); i++ { fmt.Println(\u0026#34;i:\u0026#34;, i, \u0026#34;nums\u0026#34;, nums[i]) } //数组的遍历方法2 //所有的 for-range 循环都会被转换成不包含复杂结构、只包含基本表达式的for语句 //对于所有的 range 循环，Go 语言都会在编译期将原切片或者数组赋值给一个新变量 ha，在赋值的 //过程中就发生了拷贝，而我们又通过 len 关键字预先获取了切片的长度，所以在循环中追加新的元素 //也不会改变循环执行的次数 for key, value := range nums { fmt.Println(\u0026#34;key:\u0026#34;, key, \u0026#34;value:\u0026#34;, value) } //3. //在go语言如果想省略一个值可以用下划线_ //如果两个值都想省略不能:=而用= for _, value := range nums { value += 1 //·· fmt.Println(\u0026#34;省略Key的value:\u0026#34;, value) } for _, _ = range nums { fmt.Println(\u0026#34;省略两个值：\u0026#34;) } //4.数组传递 var arr [5]int = [5]int{1, 2, 3, 4, 5} printArr(\u0026amp;arr) //数组是值类型默认是值传递 ，此处采用引用传递，函数修改后能影响源数据 fmt.Println(arr) //函数结构数组的指针 func printArr(arr *[5]int) { arr[0] = 10 for _, v := range arr { println(v) } } 指针 //go 语言也有指针 * 为取地址里面的值 //结构体成员调用 c语言 ptr-\u0026gt;name go语言 ptr.name //go语言在使用指针时，会使用内部的垃圾回收机制gc(garbage collector)，开发人员不需要手动释放内存 //c语言不许返回栈上的指针，go语言可以返回，程序在编译的时候就确定的指针的位置 //go语言在编译的时候，如果发现有必须要会将变量分配到堆上 //1.第一种定义指针 name := \u0026#34;mika\u0026#34; ptr := \u0026amp;name fmt.Println(\u0026#34;name:\u0026#34;, name, \u0026#34;ptr:\u0026#34;, ptr, \u0026#34;*ptr:\u0026#34;, *ptr) //2.第二种定义指针 age := new(int) fmt.Println(\u0026#34;age:\u0026#34;, age) *age = 10 fmt.Println(\u0026#34;*age:\u0026#34;, *age) //可以返回栈上面的指针，因为在编译的时候，会自动判断，将city这个变量分配到堆上面 ptr = test() fmt.Println(\u0026#34;ptr:\u0026#34;, ptr) // 定义函数返回一个指针，go语言函数的返回值写在后面 func test() *string { //作为局部变量函数执行完后应该会被释放 city := \u0026#34;beijing\u0026#34; return \u0026amp;city } 不支持的运算符 ++i --i c=a\u0026gt;b?3:4 go语言不支持三目运算符三目运算符 0在go语言中不能表示逻辑 否 if 0{ fmt.Println(1) } 字符串 //1.定义 var str string str = \u0026#34;aaa\u0026#34; name := \u0026#34;duke\u0026#34; //2.go语言按照原格式输入字符串加 `` usage := ` sfds nsi ` //3.字符串长度访问 strLength := len(name) //4.拼接 使用strings.Builder 效率更高 i := \u0026#34;mikasa : \u0026#34; j := \u0026#34;like\u0026#34; fmt.Println(\u0026#34;字符串拼接：\u0026#34;, i+j) //字符串截取 左闭右开 fmt.Println(\u0026#34;字符串截取:\u0026#34;, i[2:]) fmt.Println(\u0026#34;字符串截取:\u0026#34;, i[:2]) fmt.Println(\u0026#34;字符串截取:\u0026#34;, i[1:3]) //可直接使用字符串进行比较，使用ascii表 if i \u0026gt; j { fmt.Println(2) } 枚举 const { BEIJING = iota //iota默认等于0 SHANGHAI //iota=1 SHENZHEN //iota=2 } 切片 //切片，它的底层也是数组，可动态的修改长度 adress := []string{\u0026#34;北京\u0026#34;, \u0026#34;上海\u0026#34;, \u0026#34;广州\u0026#34;, \u0026#34;深圳\u0026#34;} //追加元素 adress1 := append(adress, \u0026#34;长沙\u0026#34;) //2.对于切片不仅有长度的概念还有容量的概念 容量不够时为小于1024时翻倍增长 for i := 0; i \u0026lt; 50; i++ { nums = append(nums, i) fmt.Println(\u0026#34;len:\u0026#34;, len(nums), \u0026#34;cap:\u0026#34;, cap(nums)) } 切片注意点 names := []string{\u0026#34;beijing\u0026#34;, \u0026#34;shanghai\u0026#34;, \u0026#34;shenzhen\u0026#34;, \u0026#34;changsha\u0026#34;} //基于names创建一个数组 names1 := [3]string{} names1[0] = names[0] names1[1] = names[1] names1[2] = names[2] //修改 names1[2] = \u0026#34;深圳\u0026#34; fmt.Println(\u0026#34;names:\u0026#34;, names) // fmt.Println(\u0026#34;names1:\u0026#34;, names1) //深圳 //基于切片创建一个新数组,属于引用之前的数组，如果修改数据之前的数据也会发生改变 names2 := names1[0:3] fmt.Println(\u0026#34;修改前names1:\u0026#34;, names1, \u0026#34;修改前names2:\u0026#34;, names2) names2[2] = \u0026#34;广州\u0026#34; fmt.Println(\u0026#34;修改后names1:\u0026#34;, names1, \u0026#34;修改后names2:\u0026#34;, names2) //1.如果从0开始截取,: 左边可以省略 names3 := names[:2] fmt.Println(\u0026#34;names3[:2]:\u0026#34;, names3) //2.如果截取数组最后一个元素，冒号右边可以省略 names3 = names[1:] fmt.Println(\u0026#34;截取到最后一个元素names3[1:]:\u0026#34;, names3) //3.如果截取所有元素，冒号左右都可以省略 names3 = names[:] fmt.Println(\u0026#34;截取所有元素[:]:\u0026#34;, names3) //4.对字符串截取 str := \u0026#34;abcd\u0026#34; s1 := str[1:] fmt.Println(\u0026#34;字符串截取:\u0026#34;, s1) //5.可以在创建空切片的时候，明确指定容量，这样可以提高运行效率 //创建一个容量为20的切片，当前长度为0的string //make的时候，初始值类型都是对应的零值类型 bool -\u0026gt; false 字符串 -\u0026gt; 空 数字-\u0026gt;0 str2 := make([]string, 10, 20) //第三个参数不是必须 ，如果未填写容量则与长度相等 fmt.Println(\u0026#34;str2:\u0026#34;, str2[0]) if str2[0] == \u0026#34;\u0026#34; { fmt.Println(\u0026#34;为空\u0026#34;) } fmt.Println(\u0026#34;str2-len:\u0026#34;, len(str2), \u0026#34;str2-cap:\u0026#34;, cap(str2)) str2[0] = \u0026#34;hello\u0026#34; str2[1] = \u0026#34;world\u0026#34; //6.如果想让切片完全独立于原始数组，可以用copy()函数 str3 := make([]string, len(str2)) copy(str3, str2[:]) //str3完全独立于原始数组，修改后不会对原始数组产生影响 str3[0] = \u0026#34;mikasa\u0026#34; fmt.Println(\u0026#34;复制的str3:\u0026#34;, str3, \u0026#34;原str2:\u0026#34;, str2) 字典 //1.定义一个字典，此时还不能赋值，因为还未初始化，它是空的 var namesM map[int]string //2.分配空间，可以指定长度或者不指定长度，指定长度性能更好 namesM = make(map[int]string) namesM[0] = \u0026#34;北京\u0026#34; //3.定义直接分配空间, nums:=make(map[int]string,10) 比较常用 idNames := make(map[int]string) //4.字典遍历 for k, v := range namesM { fmt.Println(\u0026#34;k:\u0026#34;, k, \u0026#34;v:\u0026#34;, v) } //5.如何确定一个key 在mao中,mao不存在索引越界的问题 fmt.Println(\u0026#34;索引越界不会抛异常：\u0026#34;, idNames[50]) //此句在go语言中不会抛异常 value, ok := namesM[9] //如果当前map中存在该key，value的值为 0 ，ok返回true //6.删除map中的元素 //使用自由函数delete在删除map中的元素 fmt.Println(\u0026#34;删除前idNames:\u0026#34;, idNames) delete(idNames, 0) Map不是线程安全的,如果遇到并发访问需要加锁 sync.Map 是并发安全的其内部默认加了互斥锁 函数 //1.函数的返回值在参数列表之后 //2.如果有多个返回值用圆括号包裹，用逗号分割 num := test1() d, e, _ := test2() //不需要接受的返回值可以用下划线省略 fmt.Println(num) // 多个返回值 func test2() (a int, b int, c string) { return 10, 20, \u0026#34;北京\u0026#34; } // 局部变量内存逃逸 func test4(str string) *int { num := 10 return \u0026amp;num } 迭代器 go 1.23版本中引入的迭代器 iter\n类型 含义 对应的for-range循环 iter.Seq[V] 生成单个(v)的序列 for v := range seq {\u0026hellip;} iter.Seq2[k,v] 生成键值对(k,v)的序列 for v := range seq2 {\u0026hellip;} 它们的本质是一个函数，这个函数接收另一个名为yield的函数作为参数,你可以将yield理解为\n一个传送门，迭代器的逻辑就是遍历数据，并把每个元素通过yield(element)传送出去。\n当yield返回true: 迭代器继续传送下一个元素\n当yield返回false：迭代器提前停止\niter包支持两种使用模式,for-range循环使用的是push模式,\n当你需要在更复杂的逻辑中手动控制迭代(例如一次只取一个值，或者在多个迭代器间交叉取值),使用pull模式\niter.Pull函数将Seq转为拉取迭代器.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;iter\u0026#34; \u0026#34;maps\u0026#34; ) // go 1.23中引入了iter迭代器 func main() { ///// push模式 // 使用迭代器 // 循环会驱动 Count(5) 返回的函数执行，并接收 yield 传送出来的值 for v := range Count(5) { fmt.Println(v) // 0 1 2 3 4 5 } m := map[string]int{\u0026#34;one\u0026#34;: 1, \u0026#34;two\u0026#34;: 2, \u0026#34;three\u0026#34;: 3} // 自带的迭代器 keys := maps.Keys(m) // 输出Map中所有的key，每次输出的顺序不能保证一样 for v := range keys { fmt.Println(v) } values := maps.Values(m) // 输出map中所有的值 for v := range values { fmt.Println(v) } //// pull 模式 手动控制,或者 一个一个拉取 next, stop := iter.Pull(Count(5)) defer stop() // 确保迭代器资源被正确清理 // 手动拉取值 v1, ok1 := next() fmt.Println(v1, ok1) v2, ok2 := next() fmt.Println(v2, ok2) // 提前停止 手动执行 stop // stop() } // 创建一个自定义迭代器 func Count(n int) iter.Seq[int] { // 返回一个 iter.Seq[int] return func(yield func(int) bool) { for i := 0; i \u0026lt; n; i++ { // 将 i 传给yield，如果yield返回false则停止 if !yield(i) { return } } } } ","date":"2023-02-25T00:00:00Z","image":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-1/image.jpg","permalink":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-1/","title":"go语言-1"},{"content":"switch cmds := os.Args //获取控制台参数,cmds[0]存储的是该程序本身 switch cmds[1] { case \u0026#34;hello\u0026#34;: fmt.Println(\u0026#34;hello\u0026#34;) case \u0026#34;world\u0026#34;: fmt.Println(\u0026#34;world\u0026#34;) fallthrough //go语言的switch默认加了break 如果需要穿透需要加关键字fallthrough case \u0026#34;1\u0026#34;: fmt.Println(\u0026#34;1\u0026#34;) fallthrough case \u0026#34;2\u0026#34;: fmt.Println(\u0026#34;1,2\u0026#34;) } LABEL func main() { LABEL: for i := 0; i \u0026lt; 5; i++ { for j := 0; j \u0026lt; 5; j++ { if j == 3 { //goto LABEL //goto 不会保存i的状态，下次进入循环时重新开始 //break LABEL //直接跳出指定位置的循环 continue LABEL //跳到指定位置，但会保存状态 } fmt.Println(\u0026#34;i:\u0026#34;, i, \u0026#34;j:\u0026#34;, j) } } } 结构体 type student struct { name string age int Sex int } type Myint int //对变量关键字重命名 s2 := student{ \u0026#34;mikasa\u0026#34;, 10, //最后一行必须加上逗号，如果不想加逗号，大括号要与参数写在一行{\u0026#34;mikasa\u0026#34;,10} } //匿名结构体 t1 := struct { name string }{name: \u0026#34;赵今麦\u0026#34;} init init在import时被调用 init函数不能被显示调用 存在多个init函数时调用顺序是随机的 如果只想调用某个包的init函数 使用下划线 _ import .. 不管包被调用多少次init函数都只执行一次 func init(){ fmt.Println(\u0026#34;第一个Init函数\u0026#34;) } defer 执行的情况\n函数执行后用于资源的释放，如文件的关闭，网络连接的关闭，数据连接的关闭 多个defer采用后进先出(LIFO)模式执行，类似于栈存储 defer执行在return之后 如果函数中发生了panic,在程序开始逐层向上抛出panic之前，会执行该函数中的所有defer语句 不执行的情况 程序正常退出或调用了os.Exit退出程序 执行了其他协程的runtime.Goexit函数 func doSomething() { defer fmt.Println(\u0026#34;deferred call in doSomething\u0026#34;) // 将会在函数结束时执行 fmt.Println(\u0026#34;doing some work\u0026#34;) // ...做一些工作... return // 此时会触发defer执行 } 类 //1. go语言里面没有类，使用结构体来模拟 type Student struct { name string age int adress string//访问修饰采用大小写的方式,大写则是对外开放 Sex int } //2. 绑定方法 func (stu Student) eat() { fmt.Println(stu.name, \u0026#34;学生吃饭\u0026#34;) stu.name = \u0026#34;sakura\u0026#34; //fmt.Println(\u0026#34;修改后:\u0026#34;, stu.name) } func (this *Student) Eat2() { fmt.Println(this.name, \u0026#34;eat2学生吃法\u0026#34;) this.name = \u0026#34;sakura\u0026#34; //fmt.Println(\u0026#34;修改后:\u0026#34;, this.name) } 组合 go不支持继承采用组合的方式来实现继承，组合是通过在一个结构体中嵌入其他结构体或者接口来实现的， 嵌入的结构体或接口的方法会被提升到外层结构体中，就好像是外层结构体自己的方法一样。\ntype People struct { name string age int } func (this *People) eat() { fmt.Println(\u0026#34;吃饭\u0026#34;) } //组合 type Man struct { People gender string } interface Go语言的接口工作原理基于一种被称为“鸭子类型”的概念，即如果它像鸭子一样走路，像鸭子一样叫，那么它就是一只鸭子。 如果类型实现了接口中的所有方法那么，它就被认为实现了该接口，而且这一切都是隐式实现的。不需要显示声明。\n实现了接口中的所有方法则是隐式实现了该接口 定义对象的行为 作为函数参数，接收任意类型的值 作为参数 //interface 实现多态.也可以接受任意数据类型 var i, k interface{} //判断数据类型 kvalue, ok := k.(int) //做类型的二次确认 if !ok { fmt.Println(\u0026#34;k不是Int\u0026#34;) } else { fmt.Println(\u0026#34;k是int,\u0026#34;, kvalue) } //最常用的场景是作为参数，根据interface的数据类型执行不同的操作 array := make([]interface{}, 3) array[0] = 1 array[1] = \u0026#34;mikasa\u0026#34; array[2] = 3.14 for _, value := range array { //这种方式的类型判断只能在switch中使用 switch v := value.(type) { case int: fmt.Printf(\u0026#34;当前为int,数据为%d\\n\u0026#34;, v) case string: fmt.Printf(\u0026#34;当前为string,数据为%s\\n\u0026#34;, v) case float64: fmt.Printf(\u0026#34;当前为folat,数据为%v\\n\u0026#34;, v) //%v自动推断数据类型 default: fmt.Printf(\u0026#34;不是合理的数据类型\u0026#34;) } } 定义行为 type IAttack interface { Attack() } // 低等级 type HumanLowLevel struct { name string level int } func (this *HumanLowLevel) Attack() { fmt.Println(\u0026#34;我是\u0026#34;, this.name, \u0026#34;等级为\u0026#34;, this.level) } // 高等级 type HumanHighLevel struct { name string level int } func (this *HumanHighLevel) Attack() { fmt.Println(\u0026#34;我是\u0026#34;, this.name, \u0026#34;等级为\u0026#34;, this.level) } // 定义一个通用接口，通过传入不同的类型，调用同一个方法实现不同的效果 func DoAttack(a IAttack) { a.Attack() } lowLevel := HumanLowLevel{ name: \u0026#34;David\u0026#34;, level: 1, } highLevel := HumanHighLevel{ name: \u0026#34;David\u0026#34;, level: 10, } DoAttack(\u0026amp;lowLevel) DoAttack(\u0026amp;highLevel) goroutine // return 返回当前函数 // exit 退出当前进程 // goexit 退出当前go程 func main() { go func() { go func() { func() { fmt.Println(\u0026#34;这是子go程内部的函数!\u0026#34;) //return //这是返回当前函数 os.Exit(-1) //退出进程 //runtime.Goexit() //退出当前go程 }() fmt.Println(\u0026#34;子go程结束!\u0026#34;) //这句会打印吗？ 会1： 不打印2 fmt.Println(\u0026#34;go 2222222222 \u0026#34;) }() time.Sleep(2 * time.Second) fmt.Println(\u0026#34;go 111111111111111\u0026#34;) }() fmt.Println(\u0026#34;这是主go程!\u0026#34;) time.Sleep(3 * time.Second) fmt.Println(\u0026#34;OVER!\u0026#34;) } ","date":"2023-02-25T00:00:00Z","image":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-2/image.jpg","permalink":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-2/","title":"go语言-2"},{"content":"chan 用在go协程之间的通信\n创建一个有缓冲区的管道,有点类似于数组但不能用下标进行访问 无缓冲区读写堵塞，nil管道读写堵塞,缓冲区无数据读堵塞，缓冲区写满时写堵塞 关闭已经关闭的管道会崩溃，向已经关闭的管道写数据会崩溃,管道读写必须对等, 堵塞在主go程会崩溃，子go程会内存泄漏 //1.创建chan numChan := make(chan int, 6) //有缓冲区 //map slice chan 使用时都需要先make,默认创建初始状态都是nil numChan2 := make(chan int) //无缓冲的管道 var testChan chan int testChan = make(chan int, 1) //关闭通道 close(testChan) v, ok := \u0026lt;-testChan//判断是否已关闭,实际是判断缓冲区里面是否还有数据 //2.读写 //写 numChan2 \u0026lt;- 100 //读 go func() { fmt.Println(\u0026#34;numChan2有缓冲区的管道读取数据,\u0026gt;\u0026gt;\u0026#34;, \u0026lt;-numChan2) }() 遍历chan numChan := make(chan int, 2) go func() { for i := 0; i \u0026lt; 10; i++ { numChan \u0026lt;- i } fmt.Println(\u0026#34;数据写入完毕\u0026#34;) close(numChan) //关闭管道放在写入端,读取端不知道什么时候会没有数据，已经关闭的关闭可以读取数据 fmt.Println(\u0026#34;关闭管道\u0026#34;) }() for v := range numChan { fmt.Println(v) if v == 0 { fmt.Println(111) } } 单向chan numChan:=make(chan int,5) //双向通道 var numChan \u0026lt;- chan int //只读管道 var numChan chan \u0026lt;- int //只写管道 //只写chan func producer(out chan\u0026lt;- int) { for i := 0; i \u0026lt; 5; i++ { //data := \u0026lt;-out 只写管道不支持读取操作 out \u0026lt;- i //fmt.Println(data) } fmt.Println(\u0026#34;数据写入完毕\u0026#34;) } //只读chan func consumer(in \u0026lt;-chan int) { for i := 0; i \u0026lt; 5; i++ { data := \u0026lt;-in //in\u0026lt;-i 不支持写入操作 fmt.Println(\u0026#34;读取到数据-\u0026#34;, data) } fmt.Println(\u0026#34;读取数据完成\u0026#34;) } select监听chan for { select { case data1 := \u0026lt;-numChan1: fmt.Println(\u0026#34;numChan1读取数据，\u0026#34;, data1) time.Sleep(1 * time.Second) case data2 := \u0026lt;-numChan2: fmt.Println(\u0026#34;numChan2读取数据,\u0026#34;, data2) time.Sleep(1 * time.Second) default: fmt.Println(\u0026#34;其他管道\u0026#34;) time.Sleep(1 * time.Second) } } Socket 服务端 //1.定义监听端口Ip ip := \u0026#34;127.0.0.1\u0026#34; port := \u0026#34;8089\u0026#34; addr := fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, ip, port) //拼接字符串 //2.开始监听 listener, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) fmt.Println(\u0026#34;监听中...\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen err\u0026gt;\u0026#34;, err) } //3.获取连接 for { conn, err := listener.Accept() //2.建立连接 fmt.Println(\u0026#34;连接建立成功\u0026#34;) if err != nil { fmt.Println(\u0026#34;accept err\u0026gt;\u0026#34;, err) } go handle(conn) } //4.读取数据 func handle(conn net.Conn) { buf := make([]byte, 1024) //make([]byte,1024) n, err := conn.Read(buf) //3.读取数据 if err != nil { fmt.Println(\u0026#34;read err\u0026gt;\u0026#34;, err) } fmt.Println(\u0026#34;读取数据client\u0026gt;\u0026gt;\u0026gt;server,len=\u0026#34;, n, \u0026#34;data=\u0026#34;, string(buf[0:n])) msg := strings.ToUpper(string(buf[0:n])) _, err = conn.Write([]byte(msg)) //5.写入数据 if err != nil { fmt.Println(\u0026#34;写入失败,\u0026#34;, err) } } 客户端 ip := \u0026#34;127.0.0.1\u0026#34; port := \u0026#34;8089\u0026#34; addr := fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, ip, port) conn, err := net.Dial(\u0026#34;tcp\u0026#34;, addr) httpClient //1.创建http客服端 httpclient := http.Client{} //2.配置请求地址 resp, err := httpclient.Get(\u0026#34;http://localhost:8089/user\u0026#34;) if err != nil { fmt.Println(\u0026#34;get err-\u0026#34;, err) } //3.获取响应体 body := resp.Body //4.读取数据 respStr, err := io.ReadAll(body) if err != nil { fmt.Println(\u0026#34;readall err\u0026gt;\u0026#34;, err) } //获取响应头 server := resp.Header.Get(\u0026#34;server\u0026#34;) date := resp.Header.Get(\u0026#34;Date\u0026#34;) //http协议参数 fmt.Println(resp.StatusCode, resp.Request.URL, resp.Request.Method, resp.Request.ContentLength, resp.Status) httpServer //1.设置监听路由 http.HandleFunc(\u0026#34;/user\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { _, _ = io.WriteString(writer, \u0026#34;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;\u0026lt;div\u0026gt;你好\u0026lt;/div\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;) }) //2.开始监听 err := http.ListenAndServe(\u0026#34;127.0.0.1:8089\u0026#34;, nil) //监听并且提供服务ListenAndServe if err != nil { fmt.Println(\u0026#34;server start err\u0026gt;\u0026#34;, err) } ","date":"2023-02-25T00:00:00Z","image":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-3/image.jpg","permalink":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-3/","title":"go语言-3"},{"content":"bufio,os包读取控制台输入 //创建读bufio reader := bufio.NewReader(os.Stdin) fmt.Println(\u0026#34;请输入内容:\u0026#34;) //读取 text, _ := reader.ReadString(\u0026#39;\\n\u0026#39;) text = strings.TrimSpace(text) fmt.Println(text) //指定输出io fmt.Fprintln(os.Stdout, \u0026#34;向标准输出写入\u0026#34;) //输出到文件 f, err := os.OpenFile(\u0026#34;./1.txt\u0026#34;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644) defer f.Close() name := \u0026#34;刘华\u0026#34; fmt.Fprintf(f, \u0026#34;文件加入信息,%s\u0026#34;, name) 读取文件的三种方式 读取整个文件 // 读取整个文件 func readFile() { context, err := os.ReadFile(\u0026#34;1.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(string(context)) } 逐行读取文件 func readFileLine() { log.Fatal(\u0026#34;log-按行读取文件\u0026#34;) f1, err := os.Open(\u0026#34;./2.txt\u0026#34;) //打开文件 if err != nil { log.Fatal(\u0026#34;1\u0026#34;, err) } defer f1.Close() //关闭文件 //按行读取文件 scanner := bufio.NewScanner(f1) //bufio.NewReader(f).ReadString(\u0026#39;\\n\u0026#39;)//bufio读取用一行 for scanner.Scan() { fmt.Printf(\u0026#34;line:%s\\n\u0026#34;, scanner.Text()) } if err := scanner.Err(); err != nil { log.Fatal(\u0026#34;2\u0026#34;, err) } log.Fatal(\u0026#34;end-按行读取文件\u0026#34;) } 分块读取 func readFileBlock() { f, err := os.Open(\u0026#34;1.txt\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() s, _ := bufio.NewReader(f).ReadString(\u0026#39;\\n\u0026#39;) //bufio读取用一行 fmt.Println(\u0026#34;bufid读取一行，\u0026#34;, s) buf := make([]byte, bufSize) for { n, err := f.Read(buf) if err != nil \u0026amp;\u0026amp; err != io.EOF { log.Fatal(err) } if err == io.EOF { break } fmt.Println(string(buf[0:n])) } } 时间触发器 //创建时间触发器 每间隔一秒 ticker := time.Tick(time.Second) for i := range ticker { fmt.Println(i) } flag包 //定义命令行参数方式1 var name string var age int var married bool var delay time.Duration flag.StringVar(\u0026amp;name, \u0026#34;name\u0026#34;, \u0026#34;张三\u0026#34;, \u0026#34;姓名\u0026#34;) flag.IntVar(\u0026amp;age, \u0026#34;age\u0026#34;, 18, \u0026#34;年龄\u0026#34;) flag.BoolVar(\u0026amp;married, \u0026#34;married\u0026#34;, false, \u0026#34;婚否\u0026#34;) flag.DurationVar(\u0026amp;delay, \u0026#34;d\u0026#34;, 0, \u0026#34;延迟时间间隔\u0026#34;) //打印默认 flag.PrintDefaults() //解析命令行参数 flag.Parse() //必须要执行解析才有返回值 fmt.Println(name, age, married, delay) //返回命令行参数后的其他参数 fmt.Println(flag.Args()) //返回命令行参数后的其他参数个数 fmt.Println(flag.NArg()) //返回使用的命令行参数个数 fmt.Println(flag.NFlag()) Log //[mikasa]2024/02/25 22:46:22.055007 D:/GoProjects/GoTest/8-默认log.go:20: 这是log1 //这是Log标记 log.SetFlags(log.Llongfile | log.Lmicroseconds | log.Ldate) //设置前缀 log.SetPrefix(\u0026#34;[mikasa]\u0026#34;) //设置将log输出到文件 f, err := os.OpenFile(\u0026#34;1.txt\u0026#34;, os.O_CREATE|os.O_APPEND, 0644) defer f.Close() if err != nil { log.Println(err) } log.SetOutput(f) log.Println(\u0026#34;这是log1\u0026#34;) log.Panicln(\u0026#34;出现错误2\u0026#34;) io包总结 文件io参数包 ioutil bufio os linux文件权限: 参数2 打开模式 参数3 权限控制 w 2 r 4 x 1 -rwxrwxrwx 0777 -rw-rw-rw 0666 f,_:=os.OpenFile(\u0026#34;1.txt\u0026#34;)//打开创建文件,返回f 支持读写 f:=os.Open(\u0026#34;1.txt\u0026#34;)//仅打开文件 返回f 支持读写 reader:=bufio.NewReader(f)//传入f缓冲读写 writer:=bufio.NewWriter(f) //写完后刷新缓冲区 writer.Flush() strcov类型转换 //字符串转整型 strconv.Atoi(\u0026#34;123\u0026#34;) //整型转字符串 //int to string a是c语言遗留问题，C语言没有string 用array代替 s := strconv.Itoa(i32) //字符串转bool b, _ := strconv.ParseBool(\u0026#34;true\u0026#34;) //参数一 数据 参数二 进制 参数三 最大溢出进制 i64, _ := strconv.ParseInt(\u0026#34;100\u0026#34;, 10, 64) fmt.Printf(\u0026#34;%T-%d\\n\u0026#34;, i64, i64) s1 := strconv.FormatInt(int64(i32), 10) sync sync.WaitGroup 等待协程 wg := \u0026amp;sync.WaitGroup{} wg.Add(1) go func(){ log.Println(\u0026#34;111\u0026#34;) wg.Done() } wg.Wait() //协程执行完后，接下来要执行的内容 ... sync.Mutex 互斥锁 读写锁 //互斥锁 mutx := \u0026amp;sync.Mutex{} mutx.Lock() //要加锁的内容.. //... mutx.Unlock() //读写锁 rwMutx := sync.RWMutex{} rwMutx.RLock() //... rwMutx.Unlock() 3.sync.Cond 同步通知\nmutx := sync.Mutex{} //创建cond传入锁的指针 cond := sync.NewCond(\u0026amp;mutx) cond.Wait()//等待 cond.Signal()//通知单个g 原子操作 var count int atomic.AddInt64(\u0026amp;count, 1) //原子的增加值 atomic.StoreInt64(\u0026amp;count,2)//原子地将一个 `int64` 类型的值存储到指定的内存地址中 atomic.LoadInt64(\u0026amp;count)//原子地加载指定内存地址的值 反射 var c = \u0026#34;3\u0026#34; a1 := reflect.TypeOf(a) a2 := reflect.ValueOf(a) fmt.Println(\u0026#34;d2-canset:\u0026#34;, d2.CanSet())//判断是否可以设置值 fmt.Println(\u0026#34;d2-type:\u0026#34;, d2.Type()) fmt.Println(\u0026#34;d2-kind:\u0026#34;, d2.Kind())//获取源类型 d3 := d1.Elem()//获取指针的值 泛型 增加代码的复用，不用类型需要处理相同逻辑时，比较适用泛型\n泛型种类: 1.泛型函数 2.泛型类型 3.泛型结构 4.泛型结构体 5.泛型receiver\n泛型限制:1.匿名结构体与匿名函数不支持泛型 2.不支持类型断言\n不支持泛型方法，只能通过recevier来实现方法的泛型处理 4. ~后的类型必须为基本类型，不能为结构类型\n定义一个泛型函数 泛型 1.函数名T int|float{} 2.函数名T interface{int|float}{}\n//泛型函数 func getMaxNum[T int | float64](a, b T) T { //比较最大值的泛型番薯 if a \u0026gt; b { return a } return b } // 泛型结构体 type Student[T interface{ *int | *string }] struct { name string data T } // 泛型函数 any类型 func printAnyType[T any](a T) { fmt.Println(\u0026#34;any:\u0026#34;, a) } // 自定义泛型 type CustomT interface { //~ 表示支持类型的衍生类型 // | 表示取并集 // 多行取交集 int | ~int64 uint8 | ~int32 } //进行手动约束 fmt.Println(getMaxNum[int](1, 2)) //编译器推断 fmt.Println(getMaxNum(2, 3)) //any 泛型 printAnyType[int](1) printAnyType[string](\u0026#34;avb\u0026#34;) printAnyType[bool](true) var data string = \u0026#34;你好\u0026#34; //泛型结构体 stu := \u0026amp;Student[*string]{name: \u0026#34;张三\u0026#34;, data: \u0026amp;data} rpc 像调用本地函数一样，调用远程函数。\n服务端 注册rpc服务对象,给对象绑定方法（1.定义类 2.绑定类方法） rpc.RegisterName(\u0026#34;服务名\u0026#34;,回调对象) 创建监听器 listener,err:=net.Listen() 建立连接 conn,err:=listener.Accpet() 将连接绑定rpc服务 rpc.ServeConn(conn) 客户端 用rpc连接服务器 conn,err:=rpc.Dial() 调用远程函数 conn.Call(\u0026#34;服务名.方法名\u0026#34;,传入参数，传出参数) rpc相关函数 注册服务 func RegisterName(name string, rcvr interface{}) error 参1：服务名。字符串类型 参2：对应rpc对象。该对象绑定方法要满足如下条件： 1）方法必须是导出的。 ----指包外可见。首字母大写 2）方法必须有两个参数，都是导出类型、内奸类型 3）方法第二个参数必须是“指针”（传出参数） 4）方法只有一个error接口接口类型的返回值 举例： type World struct{ } func (w *World)HelloWorld(name string,resp *string)error{ } 注册服务: rpc.RegisterName(\u0026#34;服务名\u0026#34;,new(World)) 绑定服务 func ServeConn(conn io.ReadWriteCloser) -- conn: 成功就建立好连接的socket rpc.ServeConn(conn) 调用远程函数 func (client *Client) Call(serviceMethod string, args interface{}, reply interface{}) error serviceMethod:\u0026#34;服务名.方法名\u0026#34; args:传入参数。方法需要的数据 reply:传出参数。定义var变量,\u0026amp;变量名 完成传参 protobuf message成员编号，可以不从1开始但是哦不能重复，编号不能使用19000-19999 可以使用message嵌套 定义数组、切片使用repeated关键字 可以使用枚举，编号必须从0开始 可以使用联合体。oneof关键字，成员编号不能重复。 //定义包名 package pb; //定义枚举类型 enum Week{ Monday=0;//枚举值必须从 0 开始 Turesday=1; } //定义消息体 message Student{ int32 age=1;//可以不从 1 开始，但不能重复 string name=2; People p=3;//消息体可以进行组合 repeated int32 score=4;//定义数组类型 //枚举 Week w=5; //联合体 oneof data{ string teacher=6; string class=7; } } //消息体可以进行嵌套 message People{ int32 weight=1; } ","date":"2023-02-25T00:00:00Z","image":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80%E6%A0%87%E5%87%86%E5%BA%93/image.jpg","permalink":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80%E6%A0%87%E5%87%86%E5%BA%93/","title":"go语言标准库"},{"content":"介绍 redis默认安装了命令行工具\nredis-cli 查看对应数据类型的帮助文档\n#查看通用的命令 help @generic help @string help @hash help @list help @set #查看命令 help KEYS help SADD ... Redis通用命令 通用命令是不分数据类型的，都可以使用的命令。通过help [command]可以查看命令的具体用法\n#KEYS:查看符合模版的所有Key KEYS * #DEL:删除一个指定的key DEL name #EXIST:判断key是否存在 EXISTS name #EXPIRE:给一个key设置有效期,有效期到期时该key会被自动删除 EXPIRE name 10 #TTL:查看一个key的剩余有效期 TTL name String类型 String类型常见命令 #设置键name值为lisi SET name lisi #获取键的值 GET name #删除 DEL name #查看所有键 KEY * #自增key的值 INCR age Key的结构 SET heima:user:1 name jack SET heima:user:1 age 12 Hash类型 Hash类型常见命令 HSET heima:user:1 name jack HGET heima:user:1 #设置多个值 HMSET heima:user:2 name lisi age 12 #获取多个值 HMGET heima:user:2 name age HKEYS heima:user:2 #删除 HDEL heima:user:1 List类型 List类型常见命令 #插入多个值 LPUSH heima:list:1 v1 v2 v3 v4 #从右边取出一个值并清除缓存的数据 RPOP heima:list:1 #等待指定时间取值 BLPOP heima:list:1 10 Set类型 Set类型常见命令 SADD s1 v1 v2 v3 SREM s1 v1 SCARD s1 SMEMBERS S1 SortedSet类型 SortedSet类型的常见命令 倒序 ZADD stus 85 jack 89 lucy 82 rose 95 tom 78 jerry 92 amy 76 miles ZREM tom ZREVRANGE stus 0 2 ZCOUNT stus 0 80 ZINCRBY stus 1 jack ZRANGE stus 0 2 持久化 AOF(append-only file) 用于将redis服务器接收到的写命令追加的文件末尾。AOF是一个文本文件，包含了Redis服务器接收到的写序列， 以及这些命令所产生的数据变更。\n追加写入：AOF文件采用追加写入的方式记录命令，不会覆盖原有数据，因此更加安全，可以避免数据丢失。 可读性 部分恢复：可以根据需要选择部分恢复，而不是向RDB文件那样只能进行全量恢复。 实时性：实时记录Redis服务器接收的写命令，因此可以实现比RDB更精确的持久化。 使用方式\nAOF 持久化方式可以通过配置文件中的appendonly参数进行开启和关闭，默认情况下是关闭的。 当开启 AOF 持久化后，Redis 服务器会在接收到写命令后将命令追加到 AOF 文件末尾，以保 证数据持久化。在启动 Redis 服务器时，如果存在 AOF 文件，则会根据文件内容重建数据。 同时，Redis 服务器会定期对AOF 文件进行重写，以减少文件大小和提高读写效率。 RDB 用于将Redis内存中的数据以快照的形式保存到硬盘上的二进制文件。RDB文件包含了Redis在某个时间点的数据快照。\n全量备份 恢复时间较长 使用方式\nRDB 持久化方式可以通过配置文件中的 save 参数进行启用和设置备份策略。同时，Redis 服务器还提供了 SAVE 和 BGSAVE 命令用于手动触发备份操作，其中 SAVE 命令会阻塞 Redis 服务器的其他操作直到备份 完成，而 BGSAVE 命令会在后台进行备份，不会阻塞其他操作。 集群 主从复制 Redis 的主从复制（Master-Slave Replication）是一种数据复制机制，用于将一个 Redis 实例（主节点）的 数据复制到多个其他 Redis 实例（从节点）上，从而实现数据的备份、读写分离和提高系统的可用性。\n主从复制是异步的，即主节点执行写操作后，并不会立即通知从节点进行同步，而是在稍后的某个时间点进行同步。 数据备份和容灾 读写分离：主节点负责处理写操作，而从节点可以处理读操作 扩展性 实时数据分析：可以通过节点进行实时数据分析，而不影响主节点的性能 哨兵 Redis 哨兵（Sentinel）是一种用于监控和管理 Redis 主从复制集群的组件，它负责监控 Redis 服务器的健康状态， 并在主节点发生故障时自动进行故障转移，以确保系统的高可用性和可靠性。哨兵通常以独立的进程运行，与 Redis 服 务器分开部署，可以部署多个哨兵构成哨兵集群。\n监控： 哨兵定期向 Redis 服务器发送 PING 命令检查服务器的健康状态，包括主节点和从节点。如果主节点或从 节点无法响应哨兵的请求，哨兵会将该节点标记为不可用。 2.故障检测： 哨兵会根据配置文件中设置的主从关系和监控频率来监测 Redis 服务器的健康状态。当主节点不可用时， 哨兵会尝试选举一个新的主节点，并将从节点切换到新的主节点上。\n3.故障转移： 当主节点发生故障时，哨兵会自动进行故障转移操作，选择一个从节点作为新的主节点，并通知其他从节 点切换到新的主节点上。故障转移过程中可以保证系统的持续可用性和数据一致性。\nCluster Redis Cluster 是 Redis 提供的一种分布式部署方式，用于将多个 Redis 节点组成一个集群，实现数据的分片存储 和高可用性。\n1.分片存储： Redis Cluster 将数据分成多个片段（slot），每个片段被分配到集群中的不同节点上进行存储。通过 分片存储可以实现数据的水平扩展，提高了系统的吞吐量和存储容量。\n2.高可用性：当主节点发生故障时可以自动进行故障转移，选举一个从节点作为新的主节点，保证了系统的持续可用性。\n3.自动化管理：自动的节点发现和配置管理，当新的节点加入集群或者节点发生故障时，集群会自动进行节点的重新配 置和重新分配数据。\n4.内部通信：使用内部通信协议进行节点之间的通信，保证了通信的安全性和可靠性，同时也提高了通信的效率。\n5.数据一致性：Redis Cluster 使用基于哈希槽的分片机制来保证数据的一致性，每个键值对都会被映射到一个特定 的哈希槽上进行存储，同一个哈希槽的数据被存储在集群中的同一个节点上。\n6.负载均衡： Redis Cluster 支持客户端的智能路由，根据键的哈希值将请求路由到相应的节点上进行处理，实现了 负载均衡和数据的均匀分布。\n过期删除 定时删除(TTL)：对每个键值设置过期时间，当键值对的过期时间到达时，执行自动删除。\n惰性删除：客服端尝试读取一个已经过期的键值对时，Redis会检查过期时间，如果过期则将其删除，并返回空值给客服端。\n定期删除：Redis会周期性(默认每秒检查10次)的随机选择一些过期键值对进行检查各删除。(Redis 中的过期删除是以键 值对为单位进行的，而不是以字段或集合为单位。当键值对被删除时，如果这个键是一个哈希表的字段，那么哈希表中的字段 也会被删除。如果键是一个集合或列表，那么集合或列表也会被删除)\n缓存穿透 Redis 缓存穿透是指恶意用户请求一个不存在于缓存和数据库中的数据，导致每次请求都直接访问数据库，从而给数据库带来巨 大的压力。为了避免缓存穿透，可以在查询数据库之前进行一些判断，比如使用布隆过滤器或者设置一个空值缓存。\n使用布隆过滤器来判断请求的键是否合法，如果不合法则直接返回空值，避免访问数据库：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/willf/bloom\u0026#34; \u0026#34;sync\u0026#34; ) var ( cache = make(map[string]string) cacheMutex sync.RWMutex filter *bloom.BloomFilter filterMutex sync.Mutex ) func init() { // 初始化布隆过滤器 filterMutex.Lock() filter = bloom.New(1000000, 5) filterMutex.Unlock() } func main() { // 模拟缓存数据 cache[\u0026#34;key1\u0026#34;] = \u0026#34;value1\u0026#34; cache[\u0026#34;key2\u0026#34;] = \u0026#34;value2\u0026#34; cache[\u0026#34;key3\u0026#34;] = \u0026#34;value3\u0026#34; // 模拟数据库查询函数 dbQuery := func(key string) string { fmt.Println(\u0026#34;Querying database for key:\u0026#34;, key) // 此处应该是真正的数据库查询操作 return \u0026#34;value from database\u0026#34; } // 查询函数包装，用于缓存穿透检测 queryWithCache := func(key string) string { cacheMutex.RLock() value, ok := cache[key] cacheMutex.RUnlock() // 检查缓存中是否存在该键 if ok { return value } // 检查布隆过滤器是否存在该键 filterMutex.Lock() exists := filter.Test([]byte(key)) filterMutex.Unlock() if !exists { // 如果布隆过滤器中不存在该键，直接返回空值 return \u0026#34;\u0026#34; } // 查询数据库 value = dbQuery(key) // 将查询结果放入缓存 cacheMutex.Lock() cache[key] = value cacheMutex.Unlock() return value } // 测试查询函数 key := \u0026#34;key4\u0026#34; // 不存在于缓存和数据库中的键 value := queryWithCache(key) if value == \u0026#34;\u0026#34; { fmt.Println(\u0026#34;Key\u0026#34;, key, \u0026#34;not found\u0026#34;) } else { fmt.Println(\u0026#34;Value for key\u0026#34;, key, \u0026#34;is\u0026#34;, value) } } 缓存雪崩 Redis 缓存雪崩是指在某个时间点，大量的缓存同时失效，导致大量的请求直接访问数据库，给数据库带来了巨大的压力， 甚至导致数据库崩溃。\n采取策略：\n1.缓存失效时间随机化：设置缓存失效时间时，可以加入一个随机因子，使得缓存失效时间在一个时间范围内随机分布， 避免大量缓存同时失效。\n2.缓存预加载：提前异步加载缓存数据，确保缓存数据的及时更新\n3.限流和熔断：请求进行限流和熔断，控制并发请求的数量，避免大量请求同时访问数据库。可以使用一些开源的限流组 件，比如 github.com/uber-go/ratelimit。\n4.多级缓存:本地缓存（内存）、分布式缓存（Redis）、CDN 缓存\n案例设置缓存失效时间的随机因子来避免缓存雪崩\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var ( cache = make(map[string]string) cacheMutex sync.RWMutex ) func init() { rand.Seed(time.Now().UnixNano()) } func main() { // 模拟缓存数据 cache[\u0026#34;key1\u0026#34;] = \u0026#34;value1\u0026#34; cache[\u0026#34;key2\u0026#34;] = \u0026#34;value2\u0026#34; cache[\u0026#34;key3\u0026#34;] = \u0026#34;value3\u0026#34; // 查询函数 queryWithCache := func(key string) string { cacheMutex.RLock() value, ok := cache[key] cacheMutex.RUnlock() if ok { return value } // 模拟数据库查询函数 dbQuery := func(key string) string { fmt.Println(\u0026#34;Querying database for key:\u0026#34;, key) // 此处应该是真正的数据库查询操作 return \u0026#34;value from database\u0026#34; } // 查询数据库 value = dbQuery(key) // 将查询结果放入缓存，并设置随机的失效时间 cacheMutex.Lock() cache[key] = value cacheMutex.Unlock() // 设置缓存失效时间，范围为 5-10 分钟 expire := time.Duration(rand.Intn(300)+300) * time.Second time.AfterFunc(expire, func() { cacheMutex.Lock() delete(cache, key) cacheMutex.Unlock() fmt.Println(\u0026#34;Cache for key\u0026#34;, key, \u0026#34;expired\u0026#34;) }) return value } // 模拟并发请求 for i := 0; i \u0026lt; 10; i++ { go func(index int) { key := fmt.Sprintf(\u0026#34;key%d\u0026#34;, index) value := queryWithCache(key) fmt.Println(\u0026#34;Value for key\u0026#34;, key, \u0026#34;is\u0026#34;, value) }(i) } // 等待所有请求完成 time.Sleep(2 * time.Second) } 缓存一致性 1.写后更新（Write-Through）：数据写入缓存之前先更新数据库\n2.读写时更新（Read-Through）：数据读取时先检查缓存，如果缓存中存在则直接返回缓存数据，否则从数据 库中读取数据并更新缓存\n3.写后刷新（Write-Behind）:数据写入数据库后异步更新缓存，即先更新数据库，再异步更新缓存。\n4.双写一致性（Dual Writing）：数据写入数据库后同时更新缓存，然后返回结果\n缓存击穿 Redis 缓存击穿是指某个热点数据突然失效或者缓存中不存在，导致大量的请求直接访问数据库，给数据库带 来了巨大的压力。\n采取措施:\n使用互斥锁：当缓存失效时，只允许一个请求访问数据库，其他请求等待该请求完成后再从缓存中获取数据。 可以使用 Go 语言的 sync.Mutex 来实现互斥锁。 使用分布式锁：使用分布式锁来确保只有一个请求访问数据库，其他请求等待锁释放后再从缓存中获取数据。 提前异步加载缓存数据 使用互斥锁\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var ( cache = make(map[string]string) cacheMutex sync.Mutex ) func main() { // 模拟缓存数据 cache[\u0026#34;key1\u0026#34;] = \u0026#34;value1\u0026#34; cache[\u0026#34;key2\u0026#34;] = \u0026#34;value2\u0026#34; cache[\u0026#34;key3\u0026#34;] = \u0026#34;value3\u0026#34; // 查询函数 queryWithCache := func(key string) string { cacheMutex.Lock() defer cacheMutex.Unlock() // 检查缓存中是否存在该键 value, ok := cache[key] if ok { return value } // 模拟数据库查询函数 dbQuery := func(key string) string { fmt.Println(\u0026#34;Querying database for key:\u0026#34;, key) // 此处应该是真正的数据库查询操作 return \u0026#34;value from database\u0026#34; } // 查询数据库 value = dbQuery(key) // 将查询结果放入缓存 cache[key] = value return value } // 模拟并发请求 for i := 0; i \u0026lt; 10; i++ { go func(index int) { key := fmt.Sprintf(\u0026#34;key%d\u0026#34;, index) value := queryWithCache(key) fmt.Println(\u0026#34;Value for key\u0026#34;, key, \u0026#34;is\u0026#34;, value) }(i) } // 等待所有请求完成 time.Sleep(2 * time.Second) } 使用分布式锁\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; \u0026#34;time\u0026#34; ) func acquireLock(client *redis.Client, lockKey string, expiration time.Duration) bool { ctx := context.Background() // 设置分布式锁，当且仅当 lockKey 不存在时设置成功 ok, err := client.SetNX(ctx, lockKey, true, expiration).Result() if err != nil { fmt.Println(\u0026#34;Failed to acquire lock:\u0026#34;, err) return false } return ok } func releaseLock(client *redis.Client, lockKey string) bool { ctx := context.Background() // 删除分布式锁 _, err := client.Del(ctx, lockKey).Result() if err != nil { fmt.Println(\u0026#34;Failed to release lock:\u0026#34;, err) return false } return true } func main() { // 初始化 Redis 客户端 client := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;localhost:6379\u0026#34;, Password: \u0026#34;\u0026#34;, // set your password DB: 0, // use default DB }) // 设置锁键和过期时间 lockKey := \u0026#34;my_lock\u0026#34; expiration := 5 * time.Second // 尝试获取分布式锁 if acquireLock(client, lockKey, expiration) { defer releaseLock(client, lockKey) fmt.Println(\u0026#34;Lock acquired, do something...\u0026#34;) // 在锁内执行需要保护的代码 } else { fmt.Println(\u0026#34;Failed to acquire lock, another process is holding it\u0026#34;) } } 分布式事务 分布式事务指的是在 Redis 中执行的一组命令，这些命令要么全部执行成功，要么全部执行 失败，类似于数据库中的事务。Redis 使用 MULTI 和 EXEC 命令来实现分布式事务。\nMULTI 命令用于开启一个事务 EXEC 命令用于执行事务队列中的命令 DISCARD 命令用于取消事务 127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; SET key1 value1 QUEUED 127.0.0.1:6379\u0026gt; SET key2 value2 QUEUED 127.0.0.1:6379\u0026gt; SET key3 value3 QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) OK 3) OK 使用go实现\n/* *在分布式事务中，并不能保证原子性，因此在实际应用中需要根据业务需求来决定是 *否使用分布式事务。如果需要保证原子性，可以考虑使用 Redis 的 WATCH 命令来实 *现乐观锁，或者使用分布式锁来保护关键操作。 */ package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; ) func main() { // 创建 Redis 客户端 client := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;localhost:6379\u0026#34;, Password: \u0026#34;\u0026#34;, // set your password DB: 0, // use default DB }) // 开启事务 ctx := context.Background() tx := client.TxPipeline() // 将要执行的命令添加到事务队列中 tx.Set(ctx, \u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;, 0) tx.Set(ctx, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;, 0) tx.Set(ctx, \u0026#34;key3\u0026#34;, \u0026#34;value3\u0026#34;, 0) // 执行事务 _, err := tx.Exec(ctx) if err != nil { fmt.Println(\u0026#34;Failed to execute transaction:\u0026#34;, err) return } fmt.Println(\u0026#34;Transaction executed successfully\u0026#34;) } ","date":"2023-02-17T00:00:00Z","image":"https://wushengyouya.github.io/p/redis%E5%9F%BA%E7%A1%80/image.png","permalink":"https://wushengyouya.github.io/p/redis%E5%9F%BA%E7%A1%80/","title":"redis基础"},{"content":"什么是GMP G:goroutine协程,创建一个约2kb大小。 M:thread线程, P:processor处理器,包含了运行goroutine的资源。如果线程想运行goroutine必须先获取P， P中还包含了可运行的G队列。\n在go中线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。 调度器和os调度器是通过M结合起来的，每个M都代表了一个内核线程，OS调度器负责把内核线程分配到CPU的核上执行。 P和M何时会被创建 P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。 M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。 特殊M0和G0 M0: M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。\nG0: 是每次启动一个M都会第一个创建的goroutine，G0仅用于负责调度的G，G0不指向任何可执行的函数，每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间，全局变量的G0是M0的G0。\nGMP模型 全局队列（Global Queue）：存放等待运行的 G。 P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 GMP调度流程 work stealing 机制 当本线程无可运行的G时，尝试从其他线程绑定的P偷取一半G，而不是销毁线程。\nhand off 机制 当本线程因为G进行系统调用堵塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。\n总结 引用\n[1]: Golang 调度器 GMP 原理与调度全分析\n","date":"2023-02-04T00:00:00Z","image":"https://wushengyouya.github.io/p/gmp%E5%8E%9F%E7%90%86/image-1.png","permalink":"https://wushengyouya.github.io/p/gmp%E5%8E%9F%E7%90%86/","title":"GMP原理"},{"content":"rpc rpc封装 // rpc服务端封装 type MyInterface interface { HelloWorld(string, *string) error } func RegisterService(i MyInterface) { rpc.RegisterName(\u0026#34;World\u0026#34;, i) } // rpc客服端封装,像调用本地函数一样调用远程函数 type MyClient struct { c *rpc.Client } func InitClient(addr string) MyClient { conn, _ := jsonrpc.Dial(\u0026#34;tcp\u0026#34;, addr) return MyClient{conn} } func (this *MyClient) HelloWorld(a string, b *string) error { return this.c.Call(\u0026#34;World.HelloWorld\u0026#34;, a, b) } rpc服务端 type World struct { } func (w *World) HelloWorld(name string, resp *string) error { *resp = name + \u0026#34;你好\u0026#34; return nil } //1.注册服务 err := rpc.RegisterName(\u0026#34;World\u0026#34;, new(World)) if err != nil { fmt.Println(\u0026#34;register err\u0026gt;\u0026#34;, err) } //2.设置监听地址 listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8089\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen err:\u0026#34;, err) } //3.监听连接 fmt.Println(\u0026#34;开始监听...\u0026#34;) conn, err := listener.Accept() if err != nil { fmt.Println(\u0026#34;accept err\u0026gt;\u0026#34;, err) } //4.绑定连接 jsonrpc.ServeConn(conn) rpc客服端 //1.连接服务 conn, err := jsonrpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8089\u0026#34;) //2.调用服务器方法 var resp string err = conn.Call(\u0026#34;World.HelloWorld\u0026#34;, \u0026#34;李白\u0026#34;, \u0026amp;resp) //err := client.HelloWorld(\u0026#34;李白 \u0026#34;, \u0026amp;resp) ","date":"2023-01-29T00:00:00Z","image":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-4/image.jpg","permalink":"https://wushengyouya.github.io/p/go%E8%AF%AD%E8%A8%80-4/","title":"go语言-4"},{"content":"树的定义 完全二叉树 树的遍历 前缀树Trie 前缀树trie又称为字典树或者单词查找树，是一种广泛应用于文本查找，路由查找的存储数据结构。\ntrie是一个多叉树结构，树中的每个节点存储一个字符，它与普通树状数据结构最大的差异是，存储数据的key不存放在单个节点中， 而是从根节点root出发一直到目标节点target node 之间的沿途路径组成。这样的构造方式最大的好处是，拥有前缀相同的字符串可以复用 公共的父节点，直到在首次出现不同字符的位置才出现分叉，形成多叉树结构。 leetcode习题\n初始化节点\ntype Trie struct { root *TrieNode //根节点 } type TrieNode struct { count int //经过该节点单词的数量 name rune //用来存储单词，可不加 children [26]*TrieNode //子节点，定义为26个字母 isEnd bool //是否为尾节点 } 插入 // 插入 func (t *Trie) insert(word string) { //node指向根节点 node := t.root //遍历单词的每个字母 for _, v := range word { if node.children[v-\u0026#39;a\u0026#39;] == nil { //确定一个字母在子节点数组中的位置 [字母-\u0026#39;a\u0026#39;]。 //等于nil说明树中不存在这个字母,创建一个新的节点存储 node.children[v-\u0026#39;a\u0026#39;] = \u0026amp;TrieNode{ name: v, children: [26]*TrieNode{}, isEnd: false, } } node = node.children[v-\u0026#39;a\u0026#39;] //存在就直接取出,node指向下一个节点 node.count++//统计经过字母的单词数量 fmt.Println(node.name, \u0026#34;-\u0026#34;, node.count) } node.isEnd = true //单词结尾 } 查找 // 搜索单词 func (t *Trie) search(word string) bool { node := t.root builder := strings.Builder{}//存储读取到的字母 for _, v := range word { if node.children[v-\u0026#39;a\u0026#39;] == nil { //树中不存在这个字母直接返回false,说明没存储这个单词 return false } builder.WriteRune(node.children[v-\u0026#39;a\u0026#39;].name) node = node.children[v-\u0026#39;a\u0026#39;]//移动到下一个节点 } fmt.Println(builder.String()) return node.isEnd//单词最后一个节点isEnd必定为true } // 查找是否以某个前缀开头,代码与search查不到,差异是不用判断是否到单词尾结点了 func (t *Trie) StartWith(prefix string) bool { node := t.root for _, v := range prefix { if node.children[v-\u0026#39;a\u0026#39;] == nil { //树中不存在这个字母 return false } node = node.children[v-\u0026#39;a\u0026#39;] } return true } 统计 // 统计应用该前缀的单词数量 func (t *Trie) CountPrefix(prefix string) int { node := t.root for _, v := range prefix { if node.children[v-\u0026#39;a\u0026#39;] == nil { return -1 } node = node.children[v-\u0026#39;a\u0026#39;] fmt.Printf(\u0026#34;count_prefix:%c-%d\\n\u0026#34;, node.name, node.count) } fmt.Printf(\u0026#34;count_prefix最后一个字母:%c\\n\u0026#34;, node.name) return node.count //返回前缀最后一个字母节点的count } 压缩前缀树 gin的路由存储使用了压缩前缀树。\n","date":"2023-01-29T00:00:00Z","image":"https://wushengyouya.github.io/p/%E6%A0%91/image.png","permalink":"https://wushengyouya.github.io/p/%E6%A0%91/","title":"树"},{"content":"测试cdn ","date":"2023-01-25T00:00:00Z","image":"https://wushengyouya.github.io/p/%E6%B5%8B%E8%AF%95%E5%9B%BE%E7%89%87/2.png","permalink":"https://wushengyouya.github.io/p/%E6%B5%8B%E8%AF%95%E5%9B%BE%E7%89%87/","title":"测试图片"},{"content":"githun action Hugo 编译后生成的是xml问题一般是主题没加载上 主题如果采用submoudle 模式，在action配置文件需要加入加载主题子模块的代码 cd you-repo-name # 初始化子模块 git submodule update --init --recursive git submodule update --recursive --remote submodule 如果推送了submodule子模块,主仓库需要执行下面的代码从远程同步一下，主仓库同步子模块的仓库后，子模块分支会指向空，需要手动切换回main分支\ngit submodule update #更新本地 git submodule update --recursive --remote # 从远程同步子模块 Hugo编译后css文件加载不出,hugo server显示正常 Hugo编译后与hugo server显示不一致 stackoverflow\nwindows换行问题 test ","date":"2023-01-24T03:27:52+08:00","image":"https://wushengyouya.github.io/p/hugo%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/image.png","permalink":"https://wushengyouya.github.io/p/hugo%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","title":"hugo踩坑记录"},{"content":"docker定义 命令解读 常见命令 docker pull 拉取 docker push 推送镜像到镜像仓库 docker build docker save docker load 本地加载镜像 docker images 查看所有镜像 docker rmi 移除镜像 docker logs docker run 创建并运行一个容器 docker start 开启容器 docker stop docker ps 查看运行的容器 docker rm 移除容器 -f #后面跟-f 强制删除 docker exec -it 容器名 bash/其它 #进入容器内部，运行命令行 docker search docker volume 数据卷 命令 挂载到本地目录 linux 创建命令别名 vi ~/.bashrc docker run -d \\ #创建并运行一个容器,-d 为后台运行 --name mysql \\ -p 3306:3306 \\ #设置端口映射 -e TZ=Asia/Shanghai -e MYSQL_ROOT_PASSWORD=123 -v /root/mysql/data:/var/lib/mysql -v /root/mysql/init:/docker-entrypoint-initdb.d -v /root/mysql/conf:/etc/mysql/conf.d mysql:5.7 #镜像名:版本号 自定义镜像 dockerfile 以java为例 网络 加入同一网络的docker容器可以通过名字进行访问 docker compose docker run -d \u0026ndash;name mysql -p 3306:3306 -e TZ=Asia/Shanghai -e MYSQL_ROOT_PASSWORD=123 -v /root/mysql/data:/var/lib/mysql -v /root/mysql/init:/docker-entrypoint-initdb.d -v /root/mysql/conf:/etc/mysql/conf.d mysql\n更新docker compose中的某个镜像 # 1.本地保存镜像文件为另一个版本号 # 编译 docker build -t metaverse:1.1 . # 保存 docker save metaverse:1.1 \u0026gt; metaverse_v1.2.tar # 2.上传本地保存的rar镜像文件 sudo rz # 3.加载镜像 docker load -i metaverse_v1.1.tar # 4.修改docker-compose.yaml文件的镜像版本号 vim docker-compose.yaml # 5.重新编译docker-compose的某一个镜像 # -d 为后台运行 --no-deps 不启动链接的服务 docker compose -f [*.yaml] up -d --no-deps --build [镜像名] docker compose -f ./metaverse_docker-compose.yaml up -d --no-deps --build metaverse # 6.查看Logs # 查看当前compose.yaml文件下的所有镜像 docker compose -f ./metaverse_docker-compose.yaml ps --services # 查看指定镜像的Log docker compose -f ./metaverse_docker-compose.yaml logs -f metaverse ","date":"2023-01-22T23:32:50+08:00","image":"https://wushengyouya.github.io/p/docker%E5%AD%A6%E4%B9%A0/111065478_p0.png","permalink":"https://wushengyouya.github.io/p/docker%E5%AD%A6%E4%B9%A0/","title":"docker学习"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2023-01-01T00:00:00Z","image":"https://wushengyouya.github.io/p/chinese-test/helena-hertz-wWZzXlDpMog-unsplash.jpg","permalink":"https://wushengyouya.github.io/p/chinese-test/","title":"chinese-test"}]